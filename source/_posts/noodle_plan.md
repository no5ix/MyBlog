---
title: noodle_plan
date: 2018-08-06 08:08:06
tags:
- noodle
categories:
- GitHub
password: '886'
---


# C++

pass
- 编译过程
- 内存泄漏的工具 vargrid..? 还有啥工具


# Go

pass


# Linux内存管理

## 虚拟内存





# 网络安全

最后就是网络安全，主要考察也是 WEB 安全，包括XSS，CSRF，SQL注入等。


# HTTP与HTTPS

HTTP 协议考察 HTTP 协议的返回码、HTTP 的方法等。需要特别指出的是 HTTPS 加密的详细过程要非常透彻，不然容易产生一种感觉好像都清楚了，但是一问就有点说不清楚。


# 分布式系统

不过极客时间的《Kafka 核心技术与实战》，我觉得讲的比较一般，不是很建议。分布式系统的就准备CAP理论、BASE理论、限流、熔断、一致性选举算法、主从架构、集群架构、异地多活、负载均衡、分层架构、微服务等。


# 挖坑

* ✓ 熟悉Python / 熟悉C++ / 会用Go 
* ✓ 熟悉Linux  / 熟悉Redis / 掌握MySQL / 了解Nginx 
* ✓ 分布式架构设计与开发经验 
* ✓ 带队管理经验一年多 
* ✓ 技术支持培训分享经验 
* ✓ 性能分析与优化经验 
* ✓ 多款上线项目的运营事务处理经验 
* ✓ 前后端协同开发经验

◼ 网易-猎手之王游戏项目(2018.9-2020.9) 

* ⚫ 苹果App Store首页多日重磅推荐, 2.5D即时多人战术竞技游戏, 主要负责核心模块 的架构设计开发与优化 
* ⚫ 服务器架构基于etcd的分布式改造, 解决全局单点问题, 重构广播框架, 整体承载提 高80% 
* ⚫ 内部开源的通用登录微服务核心开发者, 被较多项目接入使用, 提供登陆控制、排队、 验证等功能 
* ⚫ 开发定时器库替换网易服务器引擎自带的定时器库, 并暴露给Python调用, 性能提 升40% 
* ⚫ 网络优化, 平均降低延迟30ms, 增强其抗网络抖动能力, 使其在200ms延迟5%丢包 率的环境下依旧可以流畅运行且正常操作 
* ⚫ 解决服务器间歇性卡顿问题, 各种场景下的卡顿频次平均降低90%

◼ 冰川网络-FlyNet服务器引擎(2014.6-2018.9) 

* ⚫ 为公司开发的各种项目提供技术支持, 被公司广泛采用, 后期带队一年多, 负责设计 开发系统模块与培训分享, 以及开发计划的制定与人员的管理 
* ⚫ 支持TCP/UDP/可靠UDP的多线程网络库 
* ⚫ 提供RPC、二进制序列化协议传输、压缩协议包、加解密数据等功能 
* ⚫ 支持敏捷开发, 暴露接口到脚本层, 涉及到Python热更新、日志、定时器、数据持 久化等方面

◼ 个人开源-realtime-server服务器框架 
* ⚫ 目前在GitHub已有315个star 
* ⚫ 为著名开源项目kcp快速可靠传输协议贡献了通用的单头文件的会话实现, 以及移动 弱网的针对性改造, 达到了以20%流量换取代价换取35%的延迟降低效果 
* ⚫ 为著名开源项目muduo网络库贡献了添加了UDP扩展支持 


# Linux文件系统

## 软链接与硬链接

详细的可参考: https://blog.csdn.net/yangxjsun/article/details/79681229

![](/img/linux/hard_link_soft_link.jpg)

### 硬链接

普通链接一般就是指硬链接, 硬链接是新的目录条目，其引用系统中的现有文件。文件系统中的每一文件默认具有一个硬链接。为节省空间，可以不复制文件，而创建引用同一文件的新硬链接。新硬链接如果在与现有硬链接相同的目录中创建，则需要有不同的文件名，否则需要在不同的目录中。指向同一文件的所有硬链接具有相同的权限、连接数、用户/组所有权、时间戳以及文件内容。指向同一文件内容的硬链接需要在相同的文件系统中。
简单说，硬链接就是一个 inode 号对应多个文件。就是同一个文件使用了多个别名（上图中 hard link 就是 file 的一个别名，他们有共同的 inode）。

由于硬链接是有着相同 inode 号仅文件名不同的文件，因此硬链接存在以下几点特性：

* 文件有相同的 inode 及 data block；
* 只能对已存在的文件进行创建；
* 不能交叉文件系统进行硬链接的创建；
* 不能对目录进行创建，只可对文件创建；
* 删除一个硬链接文件并不影响其他有相同 inode 号的文件, 只是相应的链接计数器（link count)减1


### 软链接

(又称符号链接，即 soft link 或 symbolic link） 软链接与硬链接不同，若文件用户数据块中存放的内容是另一文件的路径名的指向，则该文件就是软连接。软链接就是一个普通文件，只是数据块内容有点特殊。软链接有着自己的 inode 号以及用户数据块。（见图2）软连接可以指向目录，而且软连接所指向的目录可以位于不同的文件系统中。

软链接特性：

* 软链接有自己的文件属性及权限等；
* 可对不存在的文件或目录创建软链接；
* 软链接可交叉文件系统；
* 软链接可对文件或目录创建；
* 创建软链接时，链接计数 i_nlink 不会增加；
* 删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接或悬挂的软链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。


## Linux 为什么多进程能够读写正在删除的文件


[进程表_文件表_inode_vnode https://www.cnblogs.com/zhaoyl/archive/2012/05/15/2502010.html](html_screen_shot/linux/进程表_文件表_inode_vnode.png)

Linux中多进程环境下，打开同一个文件，当一个进程进行读写操作，如果另外一个进程删除了这个文件，那么读写该文件的进程会发生什么呢?

* 因为文件被删除了，读写进程发生异常?
* 正在读写的进程仍然正常读写，好像没有发生什么？

学操作系统原理的时候，我们知道，linux是通过link的数量来控制文件删除，只有当一个文件不存在任何link的时候，这个文件才会被删除。

而每个文件都会有2个link计数器-- `i_count` 和 `i_nlink。``i_count`的意义是当前使用者的数量，也就是打开文件进程的个数。i_nlink的意义是介质连接的数量；或者可以理解为 `i_count`是内存引用计数器，i_nlink是硬盘引用计数器。再换句话说，当文件被某个进程引用时，`i_count` 就会增加；当创建文件的硬连接的时候，i_nlink 就会增加。

对于 rm 而言，就是减少 `i_nlink。`这里就出现一个问题，如果一个文件正在被某个进程调用，而用户却执行 rm 操作把文件删除了，会出现什么结果呢？

当用户执行 rm 操作后，ls 或者其他文件管理命令不再能够找到这个文件，但是进程却依然在继续正常执行，依然能够从文件中正确的读取内容。这是因为，rm 操作只是将 i_nlink 置为 0 了；由于文件被进程引用的缘故，`i_count` 不为 0，所以系统没有真正删除这个文件。i_nlink 是文件删除的充分条件，而 `i_count` 才是文件删除的必要条件。

基于以上只是，大家猜一下，如果在一个进程在打开文件写日志的时候，手动或者另外一个进程将这个日志删除，会发生什么情况？

是的，数据库并没有停掉。虽然日志文件被删除了，但是有一个进程已经打开了那个文件，所以向那个文件中的写操作仍然会成功，数据仍然会提交。

### 习题

Linux下两个进程可以同时打开同一个文件，这时如下描述**错误**的是(答案是4)：

1. 两个进程中分别产生生成两个独立的fd
2. 两个进程可以任意对文件进行读写操作，操作系统并不保证写的原子性
3. 进程可以通过系统调用对文件加锁，从而实现对文件内容的保护
4. 任何一个进程删除该文件时，另外一个进程会立即出现读写失败
5. 两个进程可以分别读取文件的不同部分而不会相互影响
6. 一个进程对文件长度和内容的修改另外一个进程可以立即感知


# Linux进程管理

## 创建守护进程的步骤

(两fork一set, u工文dev)
最关键的三步骤:

1. 调用fork，然后使父进程exit。
虽然子进程继承了父进程的进程组ID，但获得了一个新的进程ID，这就保证了子进程不是一个进程组的组长进程。这是下面将要进行的setsid调用的先决条件。

2. 调用setsid创建一个新会话。
使调用进程：(a)成为新会话的首进程，(b)成为一个新进程组的组长进程．(c)没有控制终端。也可概括为 : 开启一个新会话并释放它与控制终端之间的所有关联关系

3. 再次fork并杀掉首进程.
这样就确保了子进程不是一个会话首进程， 根据linux中获取终端的规则（只有会话首进程才能请求一个控制终端）， 这样进程永远不会重新请求一个控制终端


```
                   会      话
                 /     |      \
               /       |       \
             /         |         \
     前台进程组     后台进程组1     后台进程组2 ...
   /    |   \     /    |   \      /    |   \
进程1 进程2 ...  进程3 进程4 ...       ...
```

## 进程组

进程组就是一系列相互关联的进程集合，系统中的每一个进程也必须从属于某一个进程组；每个进程组中都会有一个唯一的 ID(process group id)，简称 PGID；PGID 一般等同于进程组的创建进程的 Process ID，而这个进进程一般也会被称为进程组先导 (process group leader)


## 会话

会话（session）是一个若干进程组的集合，同样的，系统中每一个进程组也都必须从属于某一个会话；一个会话只拥有最多一个控制终端（也可以没有），该终端为会话中所有进程组中的进程所共用。一个会话中前台进程组只会有一个，只有其中的进程才可以和控制终端进行交互；除了前台进程组外的进程组，都是后台进程组；和进程组先导类似，会话中也有会话先导 (session leader) 的概念，用来表示建立起到控制终端连接的进程。在拥有控制终端的会话中，session leader 也被称为控制进程(controlling process)，一般来说控制进程也就是登入系统的 shell 进程(login shell)；


## 杀死进程组或会话中的所有进程

我们可以使用该 PGID，通过 kill 命令向整个进程组发送信号：

`kill -SIGTERM -- -19701`

我们用一个负数 -19701 向进程组发送信号。如果我们传递的是一个正数，这个数将被视为进程 ID 用于终止进程。如果我们传递的是一个负数，它被视为 PGID，用于终止整个进程组。
负数来自系统调用的直接定义。

杀死会话中的所有进程与之完全不同。有些系统没有会话 ID 的概念。即使是具有会话 ID 的系统，例如 Linux，也没有提供系统调用来终止会话中的所有进程。你需要遍历 /proc 输出的进程树，收集所有的 SID，然后一一终止进程。
Pgrep 实现了遍历、收集并通过会话 ID 杀死进程的算法。使用以下命令：

`pkill -s <SID>`


## SIGHUP

SIGHUP 会在以下 3 种情况下被发送给相应的进程：

- 终端关闭时，该信号被发送到 session 首进程以及作为 job 提交的进程（即用 & 符号提交的进程）；
- session 首进程退出时，该信号被发送到该 session 中的前台进程组中的每一个进程；
- 若父进程退出导致进程组成为孤儿进程组，且该进程组中有进程处于停止状态（收到 SIGSTOP 或 SIGTSTP 信号），该信号会被发送到该进程组中的每一个进程。

例如：在我们登录 Linux 时，系统会分配给登录用户一个终端 (Session)。在这个终端运行的所有程序，包括前台进程组和后台进程组，一般都属于这个 Session。当用户退出 Linux 登录时，前台进程组和后台有对终端输出的进程将会收到 SIGHUP 信号。这个信号的默认操作为终止进程，因此前台进 程组和后台有终端输出的进程就会中止。
此外，对于与终端脱离关系的守护进程，正常情况下是永远都收不到这个信号的, 所以可以人为的发SIGHUP信号给她用于通知它做一些想要的自定义的操作, 比较常见的如重新读取配置文件操作。 比如 xinetd 超级服务程序。


## SIGCHLD与僵死进程

SIGCHLD信号,子进程结束时, 父进程会收到这个信号。如果父进程没有处理这个信号，也没有等待(waitpid)子进程，子进程虽然终止，但是还会在内核进程表中占有表项，这时的子进程称为僵尸进程。这种情 况我们应该捕捉它，或者wait它派生的子进程，或者父进程先终止，这时子进程的终止自动由init进程 来接管


## SIGPIPE

在网络编程中，SIGPIPE 这个信号是很常见的。当往一个写端关闭的管道或 socket 连接中连续写入数据时会引发 SIGPIPE 信号, 引发 SIGPIPE 信号的写操作将设置 errno 为 EPIPE。在 TCP 通信中，当通信的双方中的一方 close 一个连接时，若另一方接着发数据，根据 TCP 协议的规定，会收到一个 RST 响应报文，若再往这个服务器发送数据时，系统会发出一个 SIGPIPE 信号给进程，告诉进程这个连接已经断开了，不能再写入数据。

因为 SIGPIPE 信号的默认行为是结束进程，而我们绝对不希望因为写操作的错误而导致程序退出，尤其是作为服务器程序来说就更恶劣了。所以我们应该对这种信号加以处理，在这里，介绍处理 SIGPIPE 信号的方式：

一般给 SIGPIPE 设置 SIG_IGN 信号处理函数，忽略该信号:

`signal(SIGPIPE, SIG_IGN);`

前文说过，引发 SIGPIPE 信号的写操作将设置 errno 为 EPIPE,。所以，第二次往关闭的 socket 中写入数据时, 会返回 - 1, 同时 errno 置为 EPIPE. 这样，便能知道对端已经关闭，然后进行相应处理，而不会导致整个进程退出.


# TCP

包头长度 20个字节

## 三次握手

1. (SYN_SENT) A --------SYN----------> B (SYN_RECV)
2. (ESTABLISHED) A <----SYN + ACK----- B (SYN_RECV)
3. (ESTABLISHED) A -----ACK----------> B (ESTABLISHED)


## 四次挥手

1. (FIN_WAIT1) A ---------FIN----------> B (CLOSE_WAIT)
2. (FIN_WAIT2) A <--------ACK----------- B (CLOSE_WAIT)
3. (TIME_WAIT) A <---------FIN---------- B (LAST_ACK)
4. (TIME_WAIT) A ----------ACK---------> B (CLOSED)  
.  
. (2MSL之后)  
.  
5. (CLOSED) A


### timewait的意义

- 2msl之后网络中的数据分节全部消失, 防止影响到复用了原端口ip的新连接
- 如果b没收到最后一个ack, b就会重发fin, a如果不维护一个timewait却收到了一个fin会感觉莫名其妙然后响应一个rst, 然后b就会解释为一个错误


## tcp拥塞控制

- 快速重传: 报文段1成功接收并被确认ACK 2，接收端的期待序号为2，当报文段2丢失，报文段3失序到来，与接收端的期望不匹配，接收端重复发送冗余ACK 2。这样，如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK（其实是收到4个同样的ACK，第一个是正常的，后三个才是冗余的），发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出，大大提高了效率。这便是快速重传机制。

- 快速恢复
- 慢启动
- 拥塞避免

![](/img/tcp/tcp_congestion_control.png)


## tcp滑动窗口

![](/img/tcp/tcp_sliding_window1.png)

每个TCP连接的两端都维护一组窗口：发送窗口结构（send window structure）和接收窗口结构（receive window structure）。TCP以字节为单位维护其窗口结构。TCP头部中的窗口大小字段相对ACK号有一个字节的偏移量。发送端计算其可用窗口，即它可以立即发送的数据量。可用窗口（允许发送但还未发送）计算值为提供窗口（即由接收端通告的窗口）大小减去在传（已发送但未得到确认）的数据量。图中P1、P2、P3分别记录了窗口的左边界、下次发送的序列号、右边界。

![](/img/tcp/tcp_sliding_window2.png)

如上图所示， 随着发送端接收到返回的数据ACK，滑动窗口也随之右移。发送端根据接收端返回的ACK可以得到两个重要的信息：一是接收端期望收到的下一个字节序号；二是当前的窗口大小（再结合发送端已有的其他信息可以得出还能发送多少字节数据）。

需要注意的是：发送窗口的左边界只能右移，因为它控制的是已发送并受到确认的数据，具有累积性，不能返回；右边界可以右移也可以左移（能左移的右边界会带来一些缺陷，下文会讲到）。

接收端也维护一个窗口结构，但比发送窗口简单（只有左边界和右边界）。该窗口结构记录了已接收并确认的数据，以及它能够接收的最大序列号，该窗口能保证接收数据的正确性（避免存储重复的已接收和确认的数据，以及避免存储不应接收的数据）。由于TCP的累积ACK特性，只有当到达数据序列号等于左边界时，窗口才能向前滑动。


### 零窗口与TCP持续计时器

当窗口的左右边界重合（即窗口大小为0）时，发送端将停止发送数据直到窗口大小恢复为非零值，这样的窗口称为零窗口。当接收端重新获得可用空间，会给发送端发送一个窗口更新（window update），告知其可以继续发送数据。这样的窗口更新通常不包含数据（为纯ACK）。

但接收端发送的窗口更新是ACK报文，不能保证传输的可靠性。因此如果一个包含窗口更新的ACK丢失，通信双方就会一直处于等待状态：接收方等待接收数据（它已经发送了窗口更新），发送方等待窗口更新告知其可以继续发送，这样就会陷入死锁状态。为避免死锁发生，发送端会采用一个持续计时器间歇性地询问接收端，看其窗口是否增长。持续窗口计时器会触发窗口探测（window probe）消息的发送，强制要求接收端返回ACK。窗口探测包含一个字节的数据，采用TCP可靠传输（重传），强制要求接收端返回ACK，因此可以避免因窗口更新丢失而导致的死锁。


## ACK延迟确认机制

接收方在收到数据后，并不会立即回复ACK,而是延迟一定时间。一般ACK延迟发送的时间为200ms，但这个200ms并非收到数据后需要延迟的时间。系统有一个固定的定时器每隔200ms会来检查是否需要发送ACK包。这样做有两个目的。
1. 这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。
2. 如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。


# MySQL


## 重点参考博客截图

- [通过面试题学MySQL基础篇](html_screen_shot/mysql/通过面试题学MySQL基础篇.png)
- [通过面试题学MySQL进阶篇](html_screen_shot/mysql/通过面试题学MySQL进阶篇.png)
- [后端程序员必备：索引失效的十大杂症](html_screen_shot/mysql/后端程序员必备：索引失效的十大杂症.png)
- [MySQL_InnoDB_ MVCC机制的原理及实现](html_screen_shot/mysql/MySQL_InnoDB_MVCC机制的原理及实现.png)
- [MySQL的redo log、undo log、binlog](html_screen_shot/mysql/MySQL的redo%20log、undo%20log、binlog.png)
- [MySQL的redo log、undo log、binlog_简书](html_screen_shot/mysql/MySQL的redo%20log、undo%20log、binlog_简书.png)


## 参考网址

- https://chenjiabing666.github.io/2020/04/20/Mysql%E6%9C%80%E5%85%A8%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8D%97/
- https://blog.csdn.net/qq_41011723/article/details/105953813
- https://blog.csdn.net/qq_41011723/article/details/106028153


## redo log与binlog与undo log的区别

参考 https://www.cnblogs.com/Java3y/p/12453755.html , 写的非常好

也可参考 https://www.jianshu.com/p/68d5557c65be


### redo log

实际上Mysql的基本存储结构是页(记录都存在页里边)，所以MySQL是先把这条记录所在的页找到，然后把该页加载到内存中，将对应记录进行修改。

现在就可能存在一个问题：如果在内存中把数据改了，还没来得及落磁盘，而此时的数据库挂了怎么办？显然这次更改就丢了。

如果每个请求都需要将数据立马落磁盘之后，那速度会很慢，MySQL可能也顶不住。所以MySQL是怎么做的呢？
MySQL引入了redo log，内存写完了，然后会写一份redo log，这份redo log记载着这次在某个页上做了什么修改。
其实写redo log的时候，也会有buffer，是先写buffer，再真正落到磁盘中的。至于从buffer什么时候落磁盘，会有配置供我们配置。

写redo log也是需要写磁盘的，但它的好处就是顺序IO（我们都知道顺序IO比随机IO快非常多）。

所以，redo log的存在为了：当我们修改的时候，写完内存了，但数据还没真正写到磁盘的时候。此时我们的数据库挂了，我们可以根据redo log来对数据进行恢复。因为redo log是顺序IO，所以写入的速度很快，并且redo log记载的是物理变化（xxxx页做了xxx修改），文件的体积很小，恢复速度很快


### binlog

binlog记录了数据库表结构和表数据变更，比如update/delete/insert/truncate/create。它不会记录select（因为这没有对表没有进行变更）

binlog长什么样？

binlog我们可以简单理解为：存储着每条变更的SQL语句

redo log 保证的是数据库的 crash-safe 能力。采用的策略就是常说的“两阶段提交”。

一条update的SQL语句是按照这样的流程来执行的：

将数据页加载到内存 → 修改数据 → 更新数据 → 写redo log（状态为prepare） → 写binlog → 提交事务（数据写入成功后将redo log状态改为commit）

只有当两个日志都提交成功（刷入磁盘），事务才算真正的完成。

一旦发生系统故障（不管是宕机、断电、重启等等），都可以配套使用 redo log 与 binlog 做数据修复。


### undo log

undo log有什么用？

undo log主要有两个作用：回滚和多版本控制(MVCC)

在数据修改的时候，不仅记录了redo log，还记录undo log，如果因为某些原因导致事务失败或回滚了，可以用undo log进行回滚

undo log主要存储的也是逻辑日志，比如我们要insert一条数据了，那undo log会记录的一条对应的delete日志。我们要update一条记录时，它会记录一条对应相反的update记录。

这也应该容易理解，毕竟回滚嘛，跟需要修改的操作相反就好，这样就能达到回滚的目的。因为支持回滚操作，所以我们就能保证：“一个事务包含多个操作，这些操作要么全部执行，要么全都不执行”。【原子性】

因为undo log存储着修改之前的数据，相当于一个前版本，MVCC实现的是读写不阻塞，读的时候只要返回前一个版本的数据就行了。


### undolog和binlog和redolog不同之处总结

  - 参考 https://www.jianshu.com/p/68d5557c65be
  - redo log
     物理格式的日志，记录的是物理数据页面的修改的信息（数据库中每个页的修改），面向的是表空间、数据文件、数据页、偏移量等。
  - undo log
     逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，与redo log不同。
  - binlog
     逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
     但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息。比如delete操作的话，就对应着delete本身和其反向的insert；update操作的话，就对应着update执行前后的版本的信息；insert操作则对应着delete和insert本身的信息。
     因此可以基于binlog做到闪回功能。
  - binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用。
  - redo log是在InnoDB存储引擎层产生，而binlog是MySQL数据库的上层产生的，并且二进制日志不仅仅针对INNODB存储引擎，MySQL数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。
  - 两种日志记录的内容形式不同。MySQL的binlog是逻辑日志，可以简单认为记录的就是sql语句。而innodb存储引擎层面的重做日志是物理日志, 是数据页面的修改之后的物理记录。
  - 关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。那么当我执行一条 update 语句时，redo log 和 binlog 是在什么时候被写入的呢？这就有了我们常说的「两阶段提交」：
    - 写入：redo log（prepare）
    - 写入：binlog
    - 写入：redo log（commit）
  - 两种日志与记录写入磁盘的时间点不同，二进制日志只在事务提交完成后进行一次写入。而innodb存储引擎的重做日志在事务进行中不断地被写入，并日志不是随事务提交的顺序进行写入的。
  - 二进制日志仅在事务提交时记录，并且对于每一个事务，仅在事务提交时记录，并且对于每一个事务，仅包含对应事务的一个日志。而对于innodb存储引擎的重做日志，由于其记录是物理操作日志，因此每个事务对应多个日志条目，并且事务的重做日志写入是并发的，并非在事务提交时写入，其在文件中记录的顺序并非是事务开始的顺序。
  - binlog不是循环使用，在写满或者重启之后，会生成新的binlog文件，redo log是循环使用。
- binlog 日志是 master 推的还是 salve 来拉的？
  slave来拉的, 因为每一个slave都是完全独立的个体，所以slave完全依据自己的节奏去处理同步，


## 主从同步延迟与同步数据丢失问题

主库将变更写binlog日志，然后从库连接到主库之后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个中继日志中。接着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容，也就是在自己本地再次执行一遍SQL，这样就可以保证自己跟主库的数据是一样的。

这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行SQL的特点，在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。

而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。

所以mysql实际上在这一块有两个机制，一个是半同步复制，用来解决主库数据丢失问题；一个是并行复制，用来解决主从同步延时问题(实在解决不了只能强制读主库)。


### 半同步复制

这个所谓半同步复制，semi-sync复制，指的就是主库写入binlog日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的relay log之后，接着会返回一个ack给主库，主库接收到至少一个从库的ack之后才会认为写操作完成了。


### 并行复制
所谓并行复制，指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。


## 二阶段提交

 redo log 保证的是数据库的 crash-safe 能力。采用的策略就是常说的“两阶段提交”。

 一条update的SQL语句是按照这样的流程来执行的：

 将数据页加载到内存 → 修改数据 → 更新数据 → 写redo log（状态为prepare） → 写binlog → 提交事务（数据写入成功后将redo log状态改为commit）

 只有当两个日志都提交成功（刷入磁盘），事务才算真正的完成。

 一旦发生系统故障（不管是宕机、断电、重启等等），都可以配套使用 redo log 与 binlog 做数据修复。

### 两阶段提交机制的必要性

binlog 存在于Mysql Server层中，主要用于数据恢复；当数据被误删时，可以通过上一次的全量备份数据加上某段时间的binlog将数据恢复到指定的某个时间点的数据。
redo log 存在于InnoDB 引擎中，InnoDB引擎是以插件形式引入Mysql的，redo log的引入主要是为了实现Mysql的crash-safe能力。

假设redo log和binlog分别提交，可能会造成用日志恢复出来的数据和原来数据不一致的情况。

1）假设先写redo log再写binlog，即redo log没有prepare阶段，写完直接置为commit状态，然后再写binlog。那么如果写完redo log后Mysql宕机了，重启后系统自动用redo log 恢复出来的数据就会比
binlog记录的数据多出一些数据，这就会造成磁盘上数据库数据页和binlog的不一致，下次需要用到
binlog恢复误删的数据时，就会发现恢复后的数据和原来的数据不一致。
2）假设先写binlog再写redolog。如果写完redo log后Mysql宕机了，那么binlog上的记录就会比磁盘上数据页的记录多出一些数据出来，下次用binlog恢复数据，就会发现恢复后的数据和原来的数据不一致。

由此可见，redo log和binlog的两阶段提交是非常必要的。


## 索引

- 聚集索引是啥
  - 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据
  - 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。
  
- 外键是啥: 比如在students表中，通过class_id的字段，可以把数据与另一张表关联起来，这种列称为外键

- mysql 索引在什么情况下会失效
  - https://database.51cto.com/art/201912/607742.htm
  - 查询条件包含or，可能导致索引失效
  - 如何字段类型是字符串，where时一定用引号括起来，否则索引失效
  - like通配符可能导致索引失效。
  - 联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。
  - 在索引列上使用mysql的内置函数，索引失效
  - 对索引列运算（如，+、-、*、/），索引失效。
  - 索引字段上使用（！= 或者 < >，not in）时，可能会导致索引失效。
  - 索引字段上使用is null， is not null，可能导致索引失效。
  - 左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。
  - mysql估计使用全表扫描要比使用索引快,则不使用索引。

- mysql 的索引模型:
  在MySQL中使用较多的索引有Hash索引，B+树索引等，而我们经常使用的InnoDB存储引擎的默认索引实现为：B+树索引。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。


## 其他

- mysql 有那些存储引擎，有哪些区别
  1. MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持。
  2. MyISAM类型的表强调的是性能，其执行速度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持已经外部键等高级数据库功能。
  3. 现在一般都是选用InnoDB了，InnoDB支持行锁, 而MyISAM的全表锁，myisam的读写串行问题，并发效率锁表，效率低，MyISAM对于读写密集型应用一般是不会去选用的
  4. memory引擎一般用于临时表, 使用表级锁，没有事务机制, 虽然内存访问快，但如果频繁的读写，表级锁会成为瓶颈, 且内存昂贵..满了就亏了
  5. InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。

- mysql 主从同步怎么搞的？分哪几个过程？如果有一台新机器要加到从机里，怎么个过程。
  - ![](/img/etcd/mysql/mysql_master_slave_sync.jpg)
  - 复制的基本过程如下：
    1. 从节点上的I/O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；
    2. 主节点接收到来自从节点的I/O请求后，通过负责复制的I/O进程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log file 的以及bin-log position；从节点的I/O进程接收到内容后，将接收到的日志内容更新到本机的relay log中，并将读取到的binary log文件名和位置保存到master-info 文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；
    3. Slave 的 SQL线程检测到relay-log 中新增加了内容后，会将relay-log的内容解析成在祝节点上实际执行过的操作，并在本数据库中执行。

- 乐观锁与悲观锁的区别？
  - 悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于数据更新比较频繁的场景；
  - 乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于读多写少的场景。

- mvcc是啥?
  - MVCC (Multiversion Concurrency Control) 中文全程叫多版本并发控制，是现代数据库（包括 MySQL、Oracle、PostgreSQL 等）引擎实现中常用的处理读写冲突的手段，目的在于提高数据库高并发场景下的吞吐性能。
  - 如此一来不同的事务在并发过程中，SELECT 操作可以不加锁而是通过 MVCC 机制读取指定的版本历史记录，并通过一些手段保证保证读取的记录值符合事务所处的隔离级别，从而解决并发场景下的读写冲突。
  - https://chenjiayang.me/2019/06/22/mysql-innodb-mvcc/


## 实现事务采取了哪些技术以及思想？

★ 原子性：使用 undo log ，从而达到回滚

★ 持久性：使用 redo log，从而达到故障后恢复

★ 隔离性：使用锁以及MVCC,运用的优化思想有读写分离，读读并行，读写并行

★ 一致性：通过回滚，以及恢复，和在并发环境下的隔离做到一致性。


## mysql四个隔离级别

四个隔离级别的区别以及每个级别可能产生的问题以及实现原理: https://developer.aliyun.com/article/743691
  

# Redis

## 重点参考博客截图

- [通过面试题学Redis--基础篇](html_screen_shot/redis/通过面试题学Redis--基础篇.png)
- [通过面试题学Redis--进阶篇](html_screen_shot/redis/通过面试题学Redis--进阶篇.png)
- [压缩列表](html_screen_shot/redis/压缩列表.png)
- [有序集zset](html_screen_shot/redis/有序集zset.png)
- [zset](html_screen_shot/redis/zset.png)


## redis 数据结构有哪些？分别怎么实现的？

* String: 全是整数的时候用`整数编码int`, 当有字符串的时候用`简单动态字符串sds`编码
* HashTable: 元素比较少或者元素比较短的时候用`压缩表ziplist`(key1|val1|key2|val2|...这样存储), 其他时候就用`字典ht`
* Set: 元素全是整数的时候用`整数集合`编码(一种特殊的编码, 会使用各种规则来利用位空间, 来节省内存), 其他时候用`字典ht`编码(键为Set的元素, 值都为Null)
* List: 元素比较少或者元素比较短的时候用`压缩表ziplist`, 其他时候就用`双端列表LinkedList`编码
* ZSet: 元素比较少或者元素比较短的时候用`压缩表ziplist`(member1|score1|member2|score2|..., 按照score从小到大排列), 其他时候就用`跳跃表SkipList编码`(这个编码里包含一个字典结构和一个跳表结构, 字典用于快速查找member如`ZScore`指令的score和确定是否有这个member, 跳表用于`zrank`/`zrange`等)


## 有序集合的实现

  - 参考 http://redisbook.com/preview/object/sorted_set.html
  - 参考 https://redisbook.readthedocs.io/en/latest/datatype/sorted_set.html
  - https://blog.csdn.net/qq_41011723/article/details/105922185
  - https://redisbook.readthedocs.io/en/latest/compress-datastruct/ziplist.html
  - https://blog.csdn.net/qq_41011723/article/details/105937216
  - **编码选择规则**:
   在通过 ZADD 命令添加第一个元素到空 key 时， 程序通过检查输入的第一个元素来决定该创建什么编码的有序集。
    如果第一个元素符合以下条件的话， 就创建一个 `REDIS_ENCODING_ZIPLIST` 编码的有序集：
    - 服务器属性 server.zset_max_ziplist_entries 的值大于 0 （默认为 128 ）。
    - 元素的 member 长度小于服务器属性 server.zset_max_ziplist_value 的值（默认为 64 ）。

    否则，程序就创建一个 `REDIS_ENCODING_SKIPLIST` 编码的有序集。
    当后续有元素不满足上述两个条件的时候, 有序集合对象将转为使用 `REDIS_ENCODING_SKIPLIST` 编码.

    通俗的说就是:
      - `REDIS_ENCODING_ZIPLIST`(压缩列表ziplist): 少量成员项member, 且member的长度较短(比如是小整数或是短字符串), 那么 Redis 就会使用压缩列表来做列表键的底层实现。
      - `REDIS_ENCODING_SKIPLIST`(跳表skiplist+字典): 如果一个有序集合包含的元素数量比较多， 又或者有序集合中元素的成员（member）是比较长的字符串时， Redis 就会使用跳跃表来作为有序集合键的底层实现。
  - **`REDIS_ENCODING_SKIPLIST` 编码详解**:
    - 当使用 `REDIS_ENCODING_SKIPLIST` 编码时， 有序集元素由 redis.h/zset 结构体来保存, 而zset结构体包含 **跳表**+**字典**
    - 通过使用字典结构， 并将 member 作为键， score 作为值， 有序集可以在 O(1) 复杂度内：
      - 检查给定 member 是否存在于有序集（被很多底层函数使用）；
      - 取出 member 对应的 score 值（实现 ZSCORE 命令）。
    - 通过使用跳跃表， 可以让有序集支持以下两种操作：
      - 在 O(logN) 期望时间、 O(N) 最坏时间内根据 score 对 member 进行定位（被很多底层函数使用）；
      - 范围性查找和处理操作，这是（高效地）实现 ZRANGE 、 ZRANK 和 ZINTERSTORE 等命令的关键。
    - 所以通过同时使用字典和跳跃表， 有序集可以高效地实现按成员查找和按顺序查找两种操作。

## redis 持久化有哪几种方式，怎么选？

- rdb
  - 优势: 
    - RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。
    - 生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。
    - RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。
  - 劣势:
    - 当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。
- aof
  - 优势: 
    - AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。
    - AOF日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。
    - AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。
    - AOF日志文件的命令通过可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据
  - 劣势:
    - 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大
    - AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的


## redis 主从同步是怎样的过程？

1. 从redis发出sync要求
2. 主redis开始bgsave(并且一边开启指令buffer来存储bgsave过程中的写指令们记为`cmd`)
3. 主redis把bgsave生成的rdb发给从redis
4. 把`cmd`发送给从redis
5. 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令

**总结:**

主从刚刚连接的时候，进行全量同步；全量同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。



## redis key 的过期策略

- lru
- lfu(least frequency used, redis 4新增)
- random
- ttl


# etcd

raft 参考 https://www.jianshu.com/p/5aed73b288f7

etcd 是一个 Go 语言编写的分布式、高可用的**强一致性**键值存储系统，用于提供可靠的分布式键值(key-value)存储、配置共享和服务发现等功能。 etcd可以用于存储关键数据和实现分布式调度，它在现代化的集群运行中能够起到关键性的作用。


## etcd概念术语

- Raft： etcd所采用的保证分布式系统强一致性的算法。
- Node： 一个Raft状态机实例。
- Member： 一个etcd实例。它管理着一个Node，并且可以为客户端请求提供服务。
- Cluster： 由多个Member构成可以协同工作的etcd集群。
- Peer： 对同一个etcd集群中另外一个Member的称呼。
- Client： 向etcd集群发送HTTP请求的客户端。
- WAL： 预写式日志，etcd用于持久化存储的日志格式。
- snapshot： etcd防止WAL文件过多而设置的快照，存储etcd数据状态。
- Proxy： etcd的一种模式，为etcd集群提供反向代理服务。
- Leader： Raft算法中通过竞选而产生的处理所有数据提交的节点。
- Follower： 竞选失败的节点作为Raft中的从属节点，为算法提供强一致性保证。
- Candidate： 当Follower超过一定时间接收不到Leader的心跳时转变为Candidate开始竞选。
- Term： 某个节点成为Leader到下一次竞选时间，称为一个Term。
- Index： 数据项编号。Raft中通过Term和Index来定位数据。


## 数据读写顺序

为了保证数据的强一致性，etcd 集群中所有的数据流向都是一个方向，从 Leader （主节点）流向 Follower，也就是所有 Follower 的数据必须与 Leader 保持一致，如果不一致会被覆盖。

用户对于 etcd 集群所有节点进行读写

- 读取： 由于集群所有节点数据是强一致性的，读取可以从集群中随便哪个节点进行读取数据
- 写入： etcd 集群有 leader，如果写入往 leader 写入，可以直接写入，然后然后Leader节点会把写入分发给所有 Follower，如果往 follower 写入，然后Leader节点会把写入分发给所有 Follower


## leader 选举

假设三个节点的集群，三个节点上均运行 Timer（每个 Timer 持续时间是随机的），Raft算法使用随机 Timer 来初始化 Leader 选举流程，第一个节点率先完成了 Timer，随后它就会向其他两个节点发送成为 Leader 的请求，其他节点接收到请求后会以投票回应然后第一个节点被选举为 Leader。

成为 Leader 后，该节点会以固定时间间隔向其他节点发送通知，确保自己仍是Leader。有些情况下当 Follower 们收不到 Leader 的通知后，比如说 Leader 节点宕机或者失去了连接，其他节点会重复之前选举过程选举出新的 Leader。


## 判断数据是否写入

etcd 认为写入请求被 Leader 节点处理并分发给了多数节点后，就是一个成功的写入。那么多少节点如何判定呢，假设总结点数是 N，那么多数节点 Quorum=N/2+1。关于如何确定 etcd 集群应该有多少个节点的问题，上图的左侧的图表给出了集群中节点总数(Instances)对应的 Quorum 数量，用 Instances 减去 Quorom 就是集群中容错节点（允许出故障的节点）的数量。

所以在集群中推荐的最少节点数量是3个，因为1和2个节点的容错节点数都是0，一旦有一个节点宕掉整个集群就不能正常工作了。


## etcd 架构及解析2.1 架构图

![](//img/etcd/etcd_%20architecture.jpeg)


### 架构解析

从 etcd 的架构图中我们可以看到，etcd 主要分为四个部分。

- HTTP Server： 用于处理用户发送的 API 请求以及其它 etcd 节点的同步与心跳信息请求。
- Store： 用于处理 etcd 支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等等，是 etcd 对用户提供的大多数 API 功能的具体实现。
- Raft： Raft 强一致性算法的具体实现，是 etcd 的核心。
- WAL： Write Ahead Log（预写式日志），是 etcd 的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引以外，etcd 就通过 WAL 进行持久化存储。WAL 中，所有的数据提交前都会事先记录日志。

Snapshot 是为了防止数据过多而进行的状态快照；Entry 表示存储的具体日志内容。

通常，一个用户的请求发送过来，会经由 HTTP Server 转发给 Store 进行具体的事务处理，如果涉及到节点的修改，则交给 Raft 模块进行状态的变更、日志的记录，然后再同步给别的 etcd 节点以确认数据提交，最后进行数据的提交，再次同步。


# misc

- hashmap 是怎样实现的？
- Base64 的原理？编码后比编码前是大了还是小了。
- 非递归实现树的后序遍历。（这个比较有意思，大家可以试下）
- 秒杀系统的实现?



--------------------------------------------------------


# 以下是废弃的不用看了

pass


# 实操工具类

1. [ ] 可能会问docker, 需要把自己的项目docker化一波
2. [x] etcd


# 实操写代码类

5. [ ] 用asio+msgpack_rpc和参考了asiocore的kcpp来优化一波realtime-server
6. [ ] 完成jiffy

2. [x] 算法复习博客中的
4. [x] kcp rdc 握手 双通道


# 阅读书籍类

<!-- - [ ] malloc -->
<!-- - [ ] makefile -->
- [ ]  mysql
  - [ ] bin log
<!-- - [ ]   模板头文件可以放在cpp里么? 可以但是cpp里必须用到啥类型就要显示实例化啥类型 -->
<!-- - [ ] map insert 和中括号 -->
- [ ] text blob
<!-- - [ ] 虚拟内存, 页是啥意思 -->
- [ ] 查脉脉2.3 3.1薪资
<!-- - [ ] 为什么分代码段和数据段 -->
- [ ] 热备冷备
<!-- - [ ] 如何查看多个文件的同个字符串? grep -r -->
<!-- - [ ] 容器删除要注意什么? 迭代器失效问题 -->
- [ ] 共享内存, 如果core了会咋样
- [ ] 火焰图工具怎么做的? ptrace 么? ptrace是啥? perf
<!-- - [ ] 定位new -->
<!-- - [ ] c++一个空类会生成什么 (默认构造/析构(非虚)/赋值运算符/默认拷贝/取地址/const取地址) -->

<!-- Linux知识: SIGINT, SIGTERM, SIGSR1, SIGABRT, SIGSEGV,  -->
<!-- 进程状态(僵尸/孤儿), linux线程本质(LWP), 页表 -->
<!-- 服务器环境: 常用系统路径作用(/etc, /usr, /proc/), apt包管理使用(debian), -->
<!-- HTTP: get和post区别.  -->
<!-- query string 格式与编码; -->
<!-- curl的使用. -->
  <!-- 认识常见http header; 稍微了解https握手过程 -->
 
## 开发环境与工具

<!-- Makefile了解，能编写有多个文件的简单Makefile -->
<!-- CMake的使用.  -->
<!-- 编译, 链接过程原理; 静态库/动态库区别;  C++ name mangling, -->
<!-- ABI兼容概念； ldd命令(列出依赖库), nm命令(列出符号表), objdump命令(反编译啥的) -->
<!-- coredump本质是啥(出事得时候得程序内存快照) -->
<!-- 要-g才能用gdb查看coredump.   -->
<!-- gdb的bt, p XXX, info XXX, frame XXX, thread... -->

<!-- gcc编译常用选项:
 -D(D选项是用来在使用gcc/g++编译的时候定义宏的, gcc -DNAME=Peter -D 后面跟 key=value 表示定义key这个宏，它的内容是value)
 -I(指定头文件路径, 在你是用 #include "file" 的时候, gcc/g++ 会先在当前目录查找你所制定的头文件, 如果没有找到, 他回到默认的头文件目录找, 如果使用 -I 制定了 目录,他会先在你所制定的目录查找, 然后再按常规的顺序去找。

  对于 #include<file>, gcc/g++ 会到 -I 制定的目录查找, 查找不到, 然后将到系统的默认的头文件目录查找 。)
 -L(制定编译的时候，搜索库的路径) ...
 -l(选择链接得library)
  -w(小写w)的意思是关闭编译时的警告，也就是编译后不显示任何warning，因为有时在编译之后编译器会显示一些例如数据转换之类的警告，这些警告是我们平时可以忽略的。
-Wall选项意思是编译后显示所有警告。
-W选项类似-Wall，会显示警告，但是只显示编译器认为会出现错误的警告。 -->

<!-- vscode的使用，掌握remote插件使用(远程连服务器开发调试) -->
 
## C/C++进阶

<!-- RAII的用法(各种guard)  -->
<!-- C++11: move, -->
 <!-- lambda(语法及变量捕捉, 生命周期), -->
  <!-- shared_from_this 原理 -->
<!-- unordered_map使用,  -->
 <!-- function对象, shared_ptr, weak_ptr -->
<!-- dynamic_cast, reinterpret_cast, static_cast, const_cast. -->
<!-- 线程相关: thread, mutex, atomic变量 -->
<!-- SIGSEGV信号--segment fault常见原因 -->
<!-- 字节流指针解引用. -->
 <!-- 跨平台字节对齐问题(SIGBUS) -->
<!-- profile工具: tcmalloc的heap profiler, gperf.  -->
<!-- 了解ASAN查找内存越界问题 -->
<!-- 查内存泄漏工具 -->

## 数据库

<!-- mongo是直接存在内存里的嘛? 怎么持久化的? -->
<!-- mongo高可用? -->
<!-- MongoDB的CRUD基本使用. （官方文档教程） -->
<!-- 索引的使用及基本原理.  -->
MongoDB的sharding原理, shard key的类型及数值分布对其影响:
    MongoDB支持两种类型的shard key：

      - Hashed，数据库根据指定的字段值，算出一个哈希值，然后根据这个哈希值把数据写入相应的服务器中。它的好处是数据会分布的比较均匀，但是它只能把一个字段指定为shard key，另外对于范围的操作，它更多是一个广播的操作，没有精确地路由。
      - Ranged，按照指定字段的值的范围进行划分，支持复合shard key。这个就要求对字段值的范围有比较深入的了解，对未来也有一个相对清晰的把握。相对哈希，这种方式就可以有比较精确的路由。但是它也可能会带来数据分布不均匀，负载不能完全均衡的问题。
<!-- redis基本使用. 常用数据结构的应用场合. -->


<!-- - 看go, 写上登陆夫 -->
- [ ] 全球匹配怎么做?
<!-- - [ ] gdb core怎么弄 -->
- [ ] 全球同服怎么做?
- [ ] 根据登入登出日志画出在线曲线?

- [ ] 了解宝可梦/使命召唤的历史和玩法, 看看游戏和动画视频啥的
- [ ] 桶排序/线段树/统计树/排序树

- [x] 文件夹读写执行权限(文件夹得执行权限会影响其读权限和写权限, 进都进不去还想读写?)
- [x] 无锁队列原理是否一定比有锁快?(不一定, 如果临界区小因为有上下文切换则mutex慢, 再来看lockfree的spin，一般都遵循一个固定的格式：先把一个不变的值X存到某个局部变量A里，然后做一些计算，计算/生成一个新的对象，然后做一个CAS操作，判断A和X还是不是相等的，如果是，那么这次CAS就算成功了，否则再来一遍。如果上面这个loop里面“计算/生成一个新的对象”非常耗时并且contention很严重，那么lockfree性能有时会比mutex差。另外lockfree不断地spin引起的CPU同步cacheline的开销也比mutex版本的大。关于ABA问题)
- [x] msgpack pb 对比
- [x] mock
- [x] jit编译器的原理
7. [x] lockfree 队列原理
- [x] 怎么实现一个协程库?参考gevent, 协程池又是啥
- [x] 其他线程能看到另一个线程new出来的堆上东西
- [x] 线程是怎么切换的，上下文是啥？
- [x] 函数栈帧原理
- [x] 适配器模式
- [x] 纠删码(Erasure Coding)
- [x] pch是啥, 怎么提高编译速度的?
- [x] qos是啥?限速?答案: 从国外会国内也有很多条路，假设 aws 日本到国内，你给的钱多，qos 就把你放到质量好的链路；你免费，qos 就把你放到常规的链路上，高峰期丢包，中间运营商爱出故障
8. [x] python进阶，他的gc和，为啥不释放内存？查阅了关于python的内存机制的文章, 了解了垃圾回收的分代回收/引用计数/处理循环引用机制以及通过gc module和objgraph查询内存泄漏和循环引用的方法
8. [x] 多进程能利用上多核cpu么?
1. [x] pytho gc卡顿
1. [x] shared_ptr是否为线程安全的, 他的引用计数是安全的, 但是shared_ptr的读写则不是, 需要加锁操作
2. [x] 客户端如何同步服务器时间
8. [x] python为啥不是真的多线程: 他是真的多线程, 不过同一时间只有一个线程能拿到global interpreter lock(GIL), 所以看起来就像是单线程一样
- [x] 博客中noodle的文章
3. [x] mongodb
1. [x] 行为树
5. [x] 状态机
1. [x] 技能编辑器
- [x] 服务发现原理
- [x] 多线程编程防止死锁: 顺序加锁, 可以先释放占有的锁，然后过一段时间再试
9. [x] mro问题
6. [x] 登录流程, 并对比市面其他的token登录流程
2. [x] redis, 连接池还没看
4. [x] 排行榜, 四亿玩家的实时排行榜怎么撸?
10. [x] http post form


# 阅读代码类

<!-- 3. [  ] 时间轮, 最小堆定时器是啥? 看看muduo的定时器是啥样的, 跟最小堆实现有啥优势?最小堆是啥 -->
6. [ ] 排队服务
4. [ ] msgpack rpc, 模板复习

- [x] asiocore 怎么加密内容的? key在哪儿? 答案: 类似于https那一套
5. [x] epoll那一套可能要看一哈, 水平触发/边缘触发啥的, 要弄清楚水平触发和边缘触发的真正区别
- [x] asiocore怎么检查超时的?高效么?
6. [x] 抽空看一波muduo, 看看他怎么实现类似boost的strand的, 不然简历写网络库有点虚, 不然logger保序输出有点虚
2. [x] battle tick的fps是20? 会不会受到poll影响?
3. [x] 客户端逻辑帧率是多少?跟服务器帧率不同会有什么问题? 答:客户端若高则等, 若低则补帧
4. [x] 客户端比如像双棍的绕着转的技能, 是完全靠服务器同步pos的嘛?
5. [x] python占用比怎么算的?
4. [x] 复习c++本身找点题来做
2. [x] service gate
1. [x] aoi,  可知九宫格内广播对象集合是固定的，每次 AOI 事件不需要浪费 CPU 计算集合，链表的 插入删除在 O(1)内完成，但九宫格范围比avatar的实际视野要大，需要发送视野外的额外的 avatar 对象消息，浪费带宽，在边界处往返移动尤为明显。

      十字链表法的优点在于可以较准确计算有效的AOI 范围对象集合，大大减少视野外的无效 AOI 消息，节省网络封包量。缺点在于每次插入和移动时，需要计算AOI对象集合，比较 消耗 CPU。计算消耗取决于视野范围内的活动的avatar 对象数量，以及进出场景的频繁程 度。比较适合活动avatar不多，移动和进出场景不频繁，固定NPC 为主的PVE 向游戏。而九宫格法几乎不需要计算，缺点就是视野范围外的无效封包量很多。
2. [x] asiocore的kcp怎么处理主动disconnect的?经查证, 是直接设置两个已disconnected的标志位, 然后其他地方再判断之后做相应的逻辑


# 简历内容

- [ ] 简历每个可能思维扩散得对策提前写

2. [x] wx和my的km文章也要写, 比如aoi啥的
3. [x] py找找姜的面试题，网上常用题
5. [x] 写上zc经验
6. [x] kcp弱网络环境提升方案: dupack以及dupacks以及冗余rdc_data
4. [x] 异步日志可以看一下, 把wx的优化写上
9. [x] 查看g90doc看看wx他们写的东西, 充作zc经验, 看看能否弄到简历
1. [x] 把wx优化写进去延迟优化orm啥的- [x] 把晋升申请的文档梳理以下放到简历里
3. [x] cpp找找冰川, 大梦龙图的面试题，网上常用题


# 项目相关的阅读

4. [ ] 项目中的全局搜索怎么做的?模糊搜索算法又是啥?

<!-- 1. [ ] gate和gameManager和dbmanager有啥用 -->
<!-- 4. [ ] #6937 服务端自主-战斗服、微服务 rolling restart设计 -->
5. [ ] 运营指令那一套是怎么撸的

3. [x] 系统与功能 #21253 网络延迟稳定定位及优化
1. [x] 90的观战和录像是怎么做的?是指令重放吗?还是啥?
2. [x] 90录像怎么传上去的?那么大
2. [x] 在类里面新加一个变量reload后老的对象是没有这个新的成员变量的那新的对象呢？比如在CompCastSkill上加个成员变量test_reload = 1, 然后在start_cast上上print test_reload , reload后在训练场里加入一个新玩家, 看看他会不会print 1; 经查证, 新玩家是会打印1的, 老玩家会报trackback没有test_reload这个成员

-------------------------------------------------------------------------------------------

# 以下皆为杂项待归纳

- [ ] 系统与功能 #21253 网络延迟稳定定位及优化 
- [ ] #21733 [压测修复] 好友压测问题修复

- [x] #21256问题修复 - apply_friend时redis连接耗尽问题
- [ ] #18061 MongoDB报错优化
- [ ] #18060 MongoDB存盘报警
- [x] #14793 压测优化 - 微服务环境下的MongoDB连接优化
- [x] #14547 压测修复 - FriendService redis连接问题

- [ ] #6937 服务端自主-战斗服、微服务 rolling restart设计
- [ ] #6935 服务端自主-登录服设计
- [ ] #6936 服务端自主-游戏服、战斗服、微服务弹性扩缩容设计
- [ ] #9761 MatchService效率优化

- [ ] #15678Flyer C++化 服务器同步修改

- [ ] #15252 反作弊机制 - 录像记录
- [ ] #15262 反作弊机制 - 离线分析功能
- [ ] #15804 反作弊机制 - 离线分析功能 - 离线播放功能预研
