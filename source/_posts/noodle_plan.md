---
title: noodle_plan
date: 2018-08-06 08:08:06
tags:
- noodle
categories:
- GitHub
# password: '886'
---


# C++

pass
- 编译过程
- 内存泄漏的工具 vargrid..? 还有啥工具
3. [x] cpp找找冰川, 大梦龙图的面试题，网上常用题

# Go

pass


# Linux网络编程

* muduo
* epoll


# Linux内存管理

## Linux虚拟地址空间如何分布

Linux 使用虚拟地址空间，大大增加了进程的寻址空间，由低地址到高地址分别为：

![](/img/noodle_plan/linux/virtual_memory_mgr.jpeg)

* 只读段：该部分空间只能读，不可写；(包括：代码段、rodata 段(C常量字符串和#define定义的常量) )
* 数据段：保存全局变量、静态变量的空间；
* 堆 ：就是平时所说的动态内存， malloc/new 大部分都来源于此。其中堆顶的位置可通过函数 brk 和 sbrk 进行动态调整。
* 文件映射区域 ：如动态库、共享内存等映射物理空间的内存，一般是 mmap 函数所分配的虚拟地址空间。
* 栈：用于维护函数调用的上下文空间，一般为 8M ，可通过 ulimit –s 查看。
* 内核虚拟空间：用户代码不可见的内存区域，由内核管理(页表就存放在内核虚拟空间)。下图是 32 位系统典型的虚拟地址空间分布(来自《深入理解计算机系统》)。

## 内存分配的原理

先了解：brk()和sbrk()函数
``` c
int brk( const void *addr )
void* sbrk ( intptr_t incr );
```

这两个函数的作用主要是扩展heap的上界brk。第一个函数的参数为设置的新的brk上界地址，如果成功返回0，失败返回-1。第二个函数的参数为需要申请的内存的大小，然后返回heap新的上界brk地址。如果sbrk的参数为0，则返回的为原来的brk地址。

然后来了解：mmap

mmap函数第一种用法是映射磁盘文件到内存中；而malloc使用的mmap函数的第二种用法，即匿名映射，匿名映射不映射磁盘文件，而是向映射区申请一块内存。munmap函数是用于释放内存，第一个参数为内存首地址，第二个参数为内存的长度。接下来看下mmap函数的参数。

``` c
void *mmap(void *addr, size\_t length, int prot, int flags, int fd, off\_t offset);
int munmap(void *addr, size_t length);
```

这里要注意的是fd参数，fd为映射的文件描述符，如果是匿名映射，可以设为-1；

当申请小内存的时，malloc使用sbrk分配内存；当申请大内存时，使用mmap函数申请内存；但是这只是分配了虚拟内存，还没有映射到物理内存，当访问申请的内存时，才会因为缺页异常，内核分配物理内存。

然后接着深入：

由于brk/sbrk/mmap属于系统调用，如果每次申请内存，都调用这三个函数中的一个，那么每次都要产生系统调用开销（即cpu从用户态切换到内核态的上下文切换，这里要保存用户态数据，等会还要切换回用户态），这是非常影响性能的；其次，这样申请的内存容易产生碎片，因为堆是从低地址到高地址，如果低地址的内存没有被释放，高地址的内存就不能被回收。


### malloc和free原理

malloc: 

* 将所有空闲内存块连成链表，每个节点记录空闲内存块的地址、大小等信息
* 分配内存时，找到大小合适的块，切成两份，一分给用户，一份放回空闲链表
* free时，直接把内存块返回链表
* 解决外部碎片：将能够合并的内存块进行合并

malloc函数的实质体现在：它有一个将可用的内存块连接为一个长长的列表的所谓空闲链表。调用malloc函数时，它沿连接表寻找一个大到足以满足用户请求所需要的内存块。然后，将该内存块一分为二（一块的大小与用户请求的大小相等，另一块的大小就是剩下的字节）。接下来，将分配给用户的那块内存传给用户，并将剩下的那块（如果有的话）返回到连接表上。

这里注意，malloc找到的内存块大小一定是会大于等于我们需要的内存大小，下面会提到如果所有的内存块都比要求的小会怎么办？

调用free函数时，它将用户释放的内存块连接到空闲链上。到最后，空闲链会被切成很多的小内存片段，如果这时用户申请一个大的内存片段，那么空闲链上可能没有可以满足用户要求的片段了。于是，malloc函数请求延时，并开始在空闲链上翻箱倒柜地检查各内存片段，对它们进行整理，将相邻的小空闲块合并成较大的内存块。

在对内存块进行了 free 调用之后，我们需要做的是诸如将它们标记为未被使用的等事情，并且，在调用 malloc 时，我们要能够定位未被使用的内存块。因此， malloc返回的每块内存的起始处首先要有这个结构：

这就解释了，为什么在程序中free之后，但是堆的内存还是没有释放。

内存控制块结构定义
``` c
struct mem_control_block {
    int is_available;
    int size;
};
```
现在，您可能会认为当程序调用 malloc 时这会引发问题 —— 它们如何知道这个结构？答案是它们不必知道；在返回指针之前，我们会将其移动到这个结构之后，把它隐藏起来。这使得返回的指针指向没有用于任何其他用途的内存。那样，从调用程序的角度来看，它们所得到的全部是空闲的、开放的内存。然后，当通过 free() 将该指针传递回来时，我们只需要倒退几个内存字节就可以再次找到这个结构。

关于 malloc 获得虚存空间的实现，与 glibc 的版本有关，但大体逻辑是：

若分配内存小于 128k ，调用 sbrk() ，将堆顶指针向高地址移动，获得新的虚存空间。
若分配内存大于 128k ，调用 mmap() ，在文件映射区域中分配匿名虚存空间。

接着： VSZ为虚拟内存 RSS为物理内存

* VSZ 并不是每次 malloc 后都增长，是与上一节说的堆顶没发生变化有关，因为可重用堆顶内剩余的空间，这样的 malloc 是很轻量快速的。
* 但如果 VSZ 发生变化，基本与分配内存量相当，因为 VSZ 是计算虚拟地址空间总大小。
* RSS 的增量很少，是因为 malloc 分配的内存并不就马上分配实际存储空间，只有第一次使用，如第一次 memset 后才会分配。
* 由于每个物理内存页面大小是 4k ，不管 memset 其中的 1k 还是 5k 、 7k ，实际占用物理内存总是 4k 的倍数。所以 RSS 的增量总是 4k 的倍数。
* 因此，不是 malloc 后就马上占用实际内存，而是第一次使用时发现虚存对应的物理页面未分配，产生缺页中断，才真正分配物理页面，同时更新进程页面的映射关系。这也是 Linux 虚拟内存管理的核心概念之一。


## Buddy（伙伴）分配算法

参考: https://zhuanlan.zhihu.com/p/149581303

伙伴系统用于管理物理页，主要目的在于维护可用的连续物理空间，避免外部碎片。所有关于内存分配的操作都会与其打交道，buddy是物理内存的管理的门户

Linux 内核引入了伙伴系统算法（Buddy system），什么意思呢？就是把相同大小的页框块用链表串起来，页框块就像手拉手的好伙伴，也是这个算法名字的由来。

具体的，所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。最大可以申请1024个连续页框，对应4MB大小的连续内存。

![](/img/noodle_plan/linux/buddy_algo.jpg)

伙伴系统:  
因为任何正整数都可以由 2^n 的和组成，所以总能找到合适大小的内存块分配出去，减少了外部碎片产生 。

分配实例:  
比如：我需要申请4个页框，但是长度为4个连续页框块链表没有空闲的页框块，伙伴系统会从连续8个页框块的链表获取一个，并将其拆分为两个连续4个页框块，取其中一个，另外一个放入连续4个页框块的空闲链表中。释放的时候会检查，释放的这几个页框前后的页框是否空闲，能否组成下一级长度的块。

## Slab分配器

伙伴系统和slab不是二选一的关系，slab 内存分配器是对伙伴分配算法的补充

slab的目的在于避免内部碎片。从buddy系统获取的内存至少是一个页，也就是4K，如果仅仅需要8字节的内存，显然巨大的内部碎片无法容忍。

slab从buddy系统申请空间，将较大的连续内存拆分成一系列较小的内存块。申请空间时从slab中获取大小最相近的小块内存，这样可以有效减少内部碎片。在slab最大的块为8K，slab中所有块在物理上也是连续的。

上面说的用于内存分配的slab是通用的slab，主要用于支持kmalloc分配内存。

slab还有一个作用就是用作对象池，针对经常分配和回收的对象比如task_struct，可以分配一个slab对象池对其优化。这种slab是独立于通用的内存分配slab的，在内核中有很多这样的针对特定对象的slab。

在内核中想要分配一段连续的内存，首先向slab系统申请，如果不满足（超过两个页面，也就是8K），直接向buddy系统申请。如果还不满足（超过4M，也就是1024个页面），将无法获取到连续的物理地址。可以通过vmalloc获取虚拟地址空间连续，但物理地址不连续的更大的内存空间。

![](/img/noodle_plan/linux/buddy_algo2.png)

malloc是用户态使用的内存分配接口，最终还是向buddy申请内存，因为buddy系统是管理物理内存的门户。申请到大块内存后，再像slab一样对其进行细分维护，根据用户需要返回相应内存的指针。


## fork原理

fork函数的内存语义:

* 共享代码段, 子指向父 : 父子进程共享同一代码段, 子进程的页表项指向父进程相同的物理内存页(即数据段/堆段/栈段的各页)
* 写时复制(copy-on-write) : 内核会捕获所有父进程或子进程针对这些页面(即数据段/堆段/栈段的各页)的修改企图, 并为将要修改的页面创建拷贝, 将新的页面拷贝分配给遭内核捕获的进程, 从此父/子进程可以分别修改各自的页拷贝, 不再相互影响.

虽然fork创建的子进程不需要拷贝父进程的物理内存空间, 但是会复制父进程的空间内存页表. 例如对于10GB的redis进程, 需要复制约20MB的内存页表, 因为此fork操作耗时跟进程总内存量息息相关

# 网络安全pass

最后就是网络安全，主要考察也是 WEB 安全，包括XSS，CSRF，SQL注入等。


# HTTP与HTTPS

HTTP 协议考察 HTTP 协议的返回码、HTTP 的方法等。需要特别指出的是 HTTPS 加密的详细过程要非常透彻，不然容易产生一种感觉好像都清楚了，但是一问就有点说不清楚。

## https

HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：一般理解为HTTP+SSL/TLS，通过 SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。

那么SSL又是什么？

SSL（Secure Socket Layer，安全套接字层）：1994年为 Netscape 所研发，SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。

TLS（Transport Layer Security，传输层安全）：其前身是 SSL，它最初的几个版本（SSL 1.0、SSL 2.0、SSL 3.0）由网景公司开发，1999年从 3.1 开始被 IETF 标准化并改名，发展至今已经有 TLS 1.0、TLS 1.1、TLS 1.2 三个版本。SSL3.0和TLS1.0由于存在安全漏洞，已经很少被使用到。TLS 1.3 改动会比较大，目前还在草案阶段，目前使用最广泛的是TLS 1.1、TLS 1.2。

https 不是一种新的协议，只是 http 的通信接口部分使用了 ssl 和 tsl 协议替代，加入了加密、证书、完整性保护的功能，下面解释一下加密和证书，如下图所示

![](/img/noodle_plan/http/https_ssl.png)


### 共享密钥加密

也叫对称加密, 加密和解密公用一套秘钥，这样就会产生问题，已共享秘钥加密方式必须将秘钥传送给对方，但如果通信被监听，那么秘钥可能会被泄漏产生危险。

常见对称加密算法有des, aes


### 公开秘钥加密

公开秘钥加密使用一种非对称加密的算法，使用一对非对称的秘钥，一把叫做共有秘钥，一把叫做私有秘钥，在加密的时候，通信的一方使用共有秘钥进行加密，通信的另一方使用私有秘钥进行解密，利用这种方式不需要发送私有秘钥，也就不存在泄漏的风险了。

常见非对称加密算法有rsa


### https 加密方式

因为公开秘钥加密的方式比共享秘钥加密的方式钥消耗 cpu 资源，https 采取了混合加密的方式，来结合两者的优点。

在秘钥交换阶段使用公开加密的方式，之后建立连接后使用共享秘钥加密方式进行加密，如下图。

![](/img/noodle_plan/http/https_proc.png)


### 为什么要使用证书

因为公开加密还存在一些问题就是无法证明公开秘钥的正确性(有可能被黑客中间替换成了黑客自己的公钥, 然后黑客伪装成服务器/客户端做中间转发)，为了解决这个问题，https 采取了有数字证实认证机构和其相关机构颁发的公开秘钥证书，通信过程如下图所示。

![](/img/noodle_plan/http/https_ca.png)


解释一下上图的步骤：  
1\. 服务器将自己的公开秘钥传到数字证书认证机构  
2\. 数字证书认证机构使用自己的秘钥来对传来的服务器公钥进行加密，，并颁发数字证书  
3\. 服务器将传回的公钥证书发送给客户端，客户端使用数字机构颁发的公开秘钥来验证证书的有效性，以及公开秘钥的真实性(首先证书是CA颁发的。证书签名是先将证书信息（证书机构名称、有效期、拥有者、拥有者公钥）进行hash，再用CA的私有密钥对hash值加密而生成的。所以拦截者虽然可以拦截并篡改证书信息（主要是拥有者和拥有者的公钥），但是由于拦截者没有CA的私钥，所以无法生成正确的签名，从而导致客户端拿到签名后，用CA公有密钥对证书签名解密后值与用证书计算出来的实际hash值不一样，从而得不到客户端信任。其实这个ca公钥和私钥也就是非对称加密的思想了)  
4\. 客户端使用服务器的公开秘钥进行消息加密，后发送给服务器。  
5\. 服务器使用私有秘钥进行解密。

浏览器在安装的时候会内置可信的数字证书机构的共有秘钥，如下图所示。

![](/img/noodle_plan/http/https_browser_ca.png)

这就是为什么我们使用自己生成的证书的时候会产生安全警告的原因。

再附一张 https 的具体通信步骤和图解。

![](/img/noodle_plan/http/https_hand_shake.png)
![](/img/noodle_plan/http/https_hand_shake2.png)


## cookie和session以及token的区别

![](/img/noodle_plan/http/cookie_session.png)

* 由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，这个机制就是Session.典型的场景比如购物车，当你点击下单按钮时，由于HTTP协议无状态，所以并不知道是哪个用户操作的，所以服务端要为特定的用户创建了特定的Session，用用于标识这个用户，并且跟踪用户，这样才知道购物车里面有几本书。这个Session是保存在服务端的，有一个唯一标识。在服务端保存Session的方法很多，内存、数据库、文件都有。集群的时候也要考虑Session的转移，在大型的网站，一般会有专门的Session服务器集群，用来保存用户会话，这个时候 Session 信息都是放在内存的，使用一些缓存服务比如Memcached之类的来放 Session。
* 思考一下服务端如何识别特定的客户？这个时候Cookie就登场了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用 Cookie 来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。有人问，如果客户端的浏览器禁用了 Cookie 怎么办？一般这种情况下，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。
* Cookie其实还可以用在一些方便用户的场景下，设想你某次登陆过一个网站，下次登录的时候不想再次输入账号了，怎么办？这个信息可以写到Cookie里面，访问网站的时候，网站页面的脚本可以读取这个信息，就自动帮你把用户名给填了，能够方便一下用户。这也是Cookie名称的由来，给用户的一点甜头。所以，总结一下：Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。
* 为什么需要token来替代session机制? 因为session的存储对服务器说是一个巨大的开销 ， 严重的限制了服务器扩展能力， 比如说我用两个机器组成了一个集群， 小 F 通过机器 A 登录了系统， 那 session id 会保存在机器 A 上， 假设小 F 的下一次请求被转发到机器 B 怎么办？ 机器 B 可没有小 F 的 session id 啊。有时候会采用一点小伎俩： session sticky ， 就是让小 F 的请求一直粘连在机器 A 上， 但是这也不管用， 要是机器 A 挂掉了， 还得转到机器 B 去。接下来我们介绍事实上的token标准[JWT](#JWT)


### JWT

sessionId 的方式本质是把用户状态信息维护在 server 端，token 的方式就是把用户的状态信息加密成一串 token 传给前端，然后每次发请求时把 token 带上，传回给服务器端；服务器端收到请求之后，解析 token 并且验证相关信息(用jwt的header里的加密方式然后根据自己的不公开的密钥把jwt中的payload用加密一下得到一个签名 s, 然后用s对比看看是不是跟jwt里的signature相等, 相等则说明token对了)；

备注: 对于数据校验，专门的消息认证码生成算法, HMAC - 一种使用单向散列函数构造消息认证码的方法，其过程是不可逆的、唯一确定的，并且使用密钥来生成认证码，其目的是防止数据在传输过程中被篡改或伪造。将原始数据与认证码一起传输，数据接收端将原始数据使用相同密钥和相同算法再次生成认证码，与原有认证码进行比对，校验数据的合法性。


所以跟第一种登录方式最本质的区别是：通过解析 token 的计算时间换取了 session 的存储空间

业界通用的加密方式是 jwt, jwt 的具体格式如图：  

![](/img/noodle_plan/http/jwt1.png)


简单的介绍一下 jwt，它主要由 3 部分组成：

```
header 头部
{
  "alg": "HS256",
  "typ": "JWT"
}
payload 负载
{
  "sub": "1234567890",
  "name": "John Doe",
  "iat": 1516239022,
  "exp": 1555341649998
}
signature 签名
{
  HMACSHA256(
  base64UrlEncode(header) + "." +
  base64UrlEncode(payload),
  your-256-bit-secret
  ) secret base64 encoded
}
```

* header  
header 里面描述加密算法和 token 的类型，类型一般都是 JWT；

* payload
里面放的是用户的信息，也就是第一种登录方式中需要维护在服务器端 session 中的信息；

* signature
是对前两部分的签名，也可以理解为加密；实现需要一个密钥（secret），这个 secret 只有服务器才知道，然后使用 header 里面的算法按照如下方法来加密：
``` python
HMACSHA256(
  base64UrlEncode(header) + "." +
  base64UrlEncode(payload),
  secret)
```

总之，最后的 `jwt = base64url(header) + "." + base64url(payload) + "." + signature`

jwt 可以放在 response 中返回，也可以放在 cookie 中返回，这都是具体的返回方式，并不重要。

客户端发起请求时，官方推荐放在 HTTP header 中：

```
Authorization: Bearer <token>
```

这样子确实也可以解决 cookie 跨域(比如移动平台上对cookie支持不好)的问题，不过具体放在哪儿还是根据业务场景来定，并没有一定之规。


## Connection: keep-alive是干嘛的?

在早期的HTTP/1.0中，每次http请求都要创建一个连接，而创建连接的过程需要消耗资源和时间，为了减少资源消耗，缩短响应时间，就需要重用连接。在后来的HTTP/1.0中以及HTTP/1.1中，引入了重用连接的机制，就是在http请求头中加入Connection: keep-alive来告诉对方这个请求响应完成后不要关闭，下一次咱们还用这个请求继续交流。协议规定HTTP/1.0如果想要保持长连接，需要在请求头中加上Connection: keep-alive，而HTTP/1.1默认是支持长连接的，有没有这个请求头都行。

要实现长连接很简单，只要客户端和服务端都保持这个http长连接即可。但问题的关键在于保持长连接后，浏览器如何知道服务器已经响应完成？在使用短连接的时候，服务器完成响应后即关闭http连接，这样浏览器就能知道已接收到全部的响应，同时也关闭连接（TCP连接是双向的）。在使用长连接的时候，响应完成后服务器是不能关闭连接的，那么它就要在响应头中加上特殊标志告诉浏览器已响应完成。

一般情况下这个特殊标志就是Content-Length，来指明响应体的数据大小，比如Content-Length: 120表示响应体内容有120个字节，这样浏览器接收到120个字节的响应体后就知道了已经响应完成。

由于Content-Length字段必须真实反映响应体长度，但实际应用中，有些时候响应体长度并没那么好获得，例如响应体来自于网络文件，或者由动态语言生成。这时候要想准确获取长度，只能先开一个足够大的内存空间，等内容全部生成好再计算。但这样做一方面需要更大的内存开销，另一方面也会让客户端等更久。这时候Transfer-Encoding: chunked响应头就派上用场了，该响应头表示响应体内容用的是分块传输，此时服务器可以将数据一块一块地分块响应给浏览器而不必一次性全部响应，待浏览器接收到全部分块后就表示响应结束。

以分块传输一段文本内容：“人的一生总是在追求自由的一生 So easy”来说明分块传输的过程，如下图所示:

[](/img/noodle_plan/http/http_alive.png)


## get和post的本质区别。

从设计初衷上来说，GET 用来实现从服务端取数据，POST 用来实现向服务端提出请求对数据做某些修改，也因此如果你向nginx用post请求静态文件，nginx会直接返回 405 not allowed，但是服务端毕竟是人实现的，你可以让 POST 做 GET 相同的事情

get请求的参数一般放在url中，但是浏览器和服务器程序对url长度还是有限制的。
post请求的参数一般放在body，你硬要放到url中也可以。

在RESTful风格中，get用于从服务器获获取数据，而post用于创建数据


## url编码urlencode是什么

RFC3986文档规定，Url中只允许包含英文字母（a-zA-Z）、数字（0-9）、-_.~4个特殊字符以及所有保留字符。

那如何对Url中的非法字符进行编码呢?
  
  Url编码通常也被称为百分号编码（Url Encoding，also known as percent-encoding），是因为它的编码方式非常简单，使用%百分号加上两位的字符——0123456789ABCDEF——代表一个字节的十六进制形式。Url编码默认使用的字符集是US-ASCII。例如a在US-ASCII码中对应的字节是0x61，那么Url编码之后得到的就是%61，我们在地址栏上输入http://g.cn/search?q=%61%62%63，实际上就等同于在google上搜索abc了。又如@符号在ASCII字符集中对应的字节为0x40，经过Url编码之后得到的是%40。
  
  对于非ASCII字符，需要使用ASCII字符集的超集进行编码得到相应的字节，然后对每个字节执行百分号编码。对于Unicode字符，RFC文档建议使用utf-8对其进行编码得到相应的字节，然后对每个字节执行百分号编码。如"中文"使用UTF-8字符集得到的字节为0xE4 0xB8 0xAD 0xE6 0x96 0x87，经过Url编码之后得到"%E4%B8%AD%E6%96%87"。
  
  如果某个字节对应着ASCII字符集中的某个非保留字符，则此字节无需使用百分号表示。例如"Url编码"，使用UTF-8编码得到的字节是0x55 0x72 0x6C 0xE7 0xBC 0x96 0xE7 0xA0 0x81，由于前三个字节对应着ASCII中的非保留字符"Url"，因此这三个字节可以用非保留字符"Url"表示。最终的Url编码可以简化成"Url%E7%BC%96%E7%A0%81" ，当然，如果你用"%55%72%6C%E7%BC%96%E7%A0%81"也是可以的。

很多HTTP监视工具或者浏览器地址栏等在显示Url的时候会自动将Url进行一次解码（使用UTF-8字符集），这就是为什么当你在Firefox中访问Google搜索中文的时候，地址栏显示的Url包含中文的缘故。但实际上发送给服务端的原始Url还是经过编码的。


## 常见的HTTP相应状态码

总之：

* 1XX：消息
* 2XX：成功
* 3XX：重定向
* 4XX：请求错误
* 5XX、6XX：服务器错误

常见状态代码、状态描述的说明如下:

* 200 OK:
请求已成功，请求所希望的响应头或数据体将随此响应返回。实际的响应将取决于所使用的请求方法。在GET请求中，响应将包含与请求的资源相对应的实体。在POST请求中，响应将包含描述或操作结果的实体。[7]
* 301 Moved Permanently:
被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个URI之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。[19]除非额外指定，否则这个响应也是可缓存的。
新的永久性的URI应当在响应的Location域中返回。除非这是一个HEAD请求，否则响应的实体中应当包含指向新的URI的超链接及简短说明。
如果这不是一个GET或者HEAD请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。
注意：对于某些使用HTTP/1.0协议的浏览器，当它们发送的POST请求得到了一个301响应的话，接下来的重定向请求将会变成GET方式。
* 400 Bad Request
由于明显的客户端错误（例如，格式错误的请求语法，太大的大小，无效的请求消息或欺骗性路由请求），服务器不能或不会处理该请求。[31]
* 401 Unauthorized（RFC 7235）
参见：HTTP基本认证、HTTP摘要认证
类似于403 Forbidden，401语义即“未认证”，即用户没有必要的凭据。[32]该状态码表示当前请求需要用户验证。该响应必须包含一个适用于被请求资源的WWW-Authenticate信息头用以询问用户信息。客户端可以重复提交一个包含恰当的Authorization头信息的请求。[33]如果当前请求已经包含了Authorization证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。
注意：当网站（通常是网站域名）禁止IP地址时，有些网站状态码显示的401，表示该特定地址被拒绝访问网站。
* 403 Forbidden
主条目：HTTP 403
服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个HEAD请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个404响应，假如它不希望让客户端获得任何信息。
* 404 Not Found
主条目：HTTP 404
请求失败，请求所希望得到的资源未被在服务器上发现，但允许用户的后续请求。[35]没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。
* 500 Internal Server Error
通用错误消息，服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。没有给出具体错误信息。[59]
* 503 Service Unavailable
由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是暂时的，并且将在一段时间以后恢复。[62]如果能够预计延迟时间，那么响应中可以包含一个Retry-After头用以标明这个延迟时间。如果没有给出这个Retry-After信息，那么客户端应当以处理500响应的方式处理它。


# 分布式系统

分布式系统的就准备CAP理论、BASE理论、限流、熔断、一致性选举算法、主从架构、集群架构、异地多活、负载均衡、分层架构、微服务等。


## 一致性的类别

1. 强一致性
  这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大。

2. 弱一致性
  这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不久承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态。

3. 最终一致性
  最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型。

## CAP理论

一个分布式系统不可能同时满足以下三个基本需求，最多只能同时满足其中两项:

- 一致性（C：Consistency）
    在分布式环境下，一致性是指数据在多个副本之间能否保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一直的状态。

    对于一个将数据副本分布在不同分布式节点上的系统来说，如果对第一个节点的数据进行了更新操作并且更新成功后，却没有使得第二个节点上的数据得到相应的更新，于是在对第二个节点的数据进行读取操作时，获取的依然是老数据（或称为脏数据），这就是典型的分布式数据不一致的情况。在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都可以读取到其最新的值，那么这样的系统就被认为具有强一致性。
  
- 可用性（A：Availability）
  可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。这里的重点是 "有限时间内" 和 "返回结果"。

  "有限时间内" 是指，对于用户的一个操作请求，系统必须能够在指定的时间内返回对应的处理结果，如果超过了这个时间范围，那么系统就被认为是不可用的。另外，"有限的时间内" 是指系统设计之初就设计好的运行指标，通常不同系统之间有很大的不同，无论如何，对于用户请求，系统必须存在一个合理的响应时间，否则用户便会对系统感到失望。

  "返回结果" 是可用性的另一个非常重要的指标，它要求系统在完成对用户请求的处理后，返回一个正常的响应结果。正常的响应结果通常能够明确地反映出队请求的处理结果，即成功或失败，而不是一个让用户感到困惑的返回结果。

- 分区容错性（P：Partition tolerance）
  分区容错性约束了一个分布式系统具有如下特性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。

  网络分区是指在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络）中，由于一些特殊的原因导致这些子网络出现网络不连通的状况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域。 需要注意的是，组成一个分布式系统的每个节点的加入与退出都可以看作是一个特殊的网络分区。
既然一个分布式系统无法同时满足一致性、可用性、分区容错性三个特点，所以我们就需要抛弃一样：

| 选择 | 说明                                                                                                                        |
| ---- | --------------------------------------------------------------------------------------------------------------------------- |
| CA   | 放弃分区容错性，加强一致性和可用性，其实就是传统的单机数据库的选择                                                          |
| AP   | 放弃一致性（这里说的一致性是强一致性），追求分区容错性和可用性，这是很多分布式系统设计时的选择，例如很多 NoSQL 系统就是如此 |
| CP   | 放弃可用性，追求一致性和分区容错性，基本不会选择，网络问题会直接让整个系统不可用                                            |

需要明确的一点是，对于一个分布式系统而言，分区容错性是一个最基本的要求。因为既然是一个分布式系统，那么分布式系统中的组件必然需要被部署到不同的节点，否则也就无所谓分布式系统了，因此必然出现子网络。而对于分布式系统而言，网络问题又是一个必定会出现的异常情况，因此分区容错性也就成为了一个分布式系统必然需要面对和解决的问题。因此系统架构师往往需要把精力花在如何根据业务特点在 C（一致性）和 A（可用性）之间寻求平衡。

# BASE 理论

BASE 是 

* Basically Available（基本可用）
* Soft state（软状态）和
* Eventually consistent（最终一致性）

三个短语的缩写。BASE 理论是对 CAP 中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结， 是基于 CAP 定理逐步演化而来的。BASE 理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。接下来看一下 BASE 中的三要素：

* 基本可用
    基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。注意，这绝不等价于系统不可用。比如：

    * 响应时间上的损失。正常情况下，一个在线搜索引擎需要在 0.5 秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了 1~2 秒

    * 系统功能上的损失：正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。

* 软状态
    软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。

* 最终一致性
    最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

总的来说，BASE 理论面向的是大型高可用可扩展的分布式系统，和传统的事物 ACID 特性是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID 特性和 BASE 理论往往又会结合在一起。


# 挖坑pass

* ✓ 熟悉Python / 熟悉C++ / 会用Go 
* ✓ 熟悉Linux  / 熟悉Redis / 掌握MySQL / 了解Nginx 
* ✓ 分布式架构设计与开发经验 
* ✓ 带队管理经验一年多 
* ✓ 技术支持培训分享经验 
* ✓ 性能分析与优化经验 
* ✓ 多款上线项目的运营事务处理经验 
* ✓ 前后端协同开发经验

◼ 网易-猎手之王游戏项目(2018.9-2020.9) 

* ⚫ 苹果App Store首页多日重磅推荐, 2.5D即时多人战术竞技游戏, 主要负责核心模块 的架构设计开发与优化 
* ⚫ 服务器架构基于etcd的分布式改造, 解决全局单点问题, 重构广播框架, 整体承载提 高80% 
* ⚫ 内部开源的通用登录微服务核心开发者, 被较多项目接入使用, 提供登陆控制、排队、 验证等功能 
* ⚫ 开发定时器库替换网易服务器引擎自带的定时器库, 并暴露给Python调用, 性能提 升40% 
* ⚫ 网络优化, 平均降低延迟30ms, 增强其抗网络抖动能力, 使其在200ms延迟5%丢包 率的环境下依旧可以流畅运行且正常操作 
* ⚫ 解决服务器间歇性卡顿问题, 各种场景下的卡顿频次平均降低90%

◼ 冰川网络-FlyNet服务器引擎(2014.6-2018.9) 

* ⚫ 为公司开发的各种项目提供技术支持, 被公司广泛采用, 后期带队一年多, 负责设计 开发系统模块与培训分享, 以及开发计划的制定与人员的管理 
* ⚫ 支持TCP/UDP/可靠UDP的多线程网络库 
* ⚫ 提供RPC、二进制序列化协议传输、压缩协议包、加解密数据等功能 
* ⚫ 支持敏捷开发, 暴露接口到脚本层, 涉及到Python热更新、日志、定时器、数据持 久化等方面

◼ 个人开源-realtime-server服务器框架 
* ⚫ 目前在GitHub已有315个star 
* ⚫ 为著名开源项目kcp快速可靠传输协议贡献了通用的单头文件的会话实现, 以及移动 弱网的针对性改造, 达到了以20%流量换取代价换取35%的延迟降低效果 
* ⚫ 为著名开源项目muduo网络库贡献了添加了UDP扩展支持 


# Linux文件系统

## 软链接与硬链接

详细的可参考: https://blog.csdn.net/yangxjsun/article/details/79681229

![](/img/noodle_plan/linux/hard_link_soft_link.jpg)

### 硬链接

普通链接一般就是指硬链接, 硬链接是新的目录条目，其引用系统中的现有文件。文件系统中的每一文件默认具有一个硬链接。为节省空间，可以不复制文件，而创建引用同一文件的新硬链接。新硬链接如果在与现有硬链接相同的目录中创建，则需要有不同的文件名，否则需要在不同的目录中。指向同一文件的所有硬链接具有相同的权限、连接数、用户/组所有权、时间戳以及文件内容。指向同一文件内容的硬链接需要在相同的文件系统中。
简单说，硬链接就是一个 inode 号对应多个文件。就是同一个文件使用了多个别名（上图中 hard link 就是 file 的一个别名，他们有共同的 inode）。

由于硬链接是有着相同 inode 号仅文件名不同的文件，因此硬链接存在以下几点特性：

* 文件有相同的 inode 及 data block；
* 只能对已存在的文件进行创建；
* 不能交叉文件系统进行硬链接的创建；
* 不能对目录进行创建，只可对文件创建；
* 删除一个硬链接文件并不影响其他有相同 inode 号的文件, 只是相应的链接计数器（link count)减1


### 软链接

(又称符号链接，即 soft link 或 symbolic link） 软链接与硬链接不同，若文件用户数据块中存放的内容是另一文件的路径名的指向，则该文件就是软连接。软链接就是一个普通文件，只是数据块内容有点特殊。软链接有着自己的 inode 号以及用户数据块。（见图2）软连接可以指向目录，而且软连接所指向的目录可以位于不同的文件系统中。

软链接特性：

* 软链接有自己的文件属性及权限等；
* 可对不存在的文件或目录创建软链接；
* 软链接可交叉文件系统；
* 软链接可对文件或目录创建；
* 创建软链接时，链接计数 i_nlink 不会增加；
* 删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接或悬挂的软链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。


## Linux 为什么多进程能够读写正在删除的文件


[进程表_文件表_inode_vnode https://www.cnblogs.com/zhaoyl/archive/2012/05/15/2502010.html](html_screen_shot/linux/进程表_文件表_inode_vnode.png)

Linux中多进程环境下，打开同一个文件，当一个进程进行读写操作，如果另外一个进程删除了这个文件，那么读写该文件的进程会发生什么呢?

* 因为文件被删除了，读写进程发生异常?
* 正在读写的进程仍然正常读写，好像没有发生什么？

学操作系统原理的时候，我们知道，linux是通过link的数量来控制文件删除，只有当一个文件不存在任何link的时候，这个文件才会被删除。

而每个文件都会有2个link计数器-- `i_count` 和 `i_nlink。``i_count`的意义是当前使用者的数量，也就是打开文件进程的个数。i_nlink的意义是介质连接的数量；或者可以理解为 `i_count`是内存引用计数器，i_nlink是硬盘引用计数器。再换句话说，当文件被某个进程引用时，`i_count` 就会增加；当创建文件的硬连接的时候，i_nlink 就会增加。

对于 rm 而言，就是减少 `i_nlink。`这里就出现一个问题，如果一个文件正在被某个进程调用，而用户却执行 rm 操作把文件删除了，会出现什么结果呢？

当用户执行 rm 操作后，ls 或者其他文件管理命令不再能够找到这个文件，但是进程却依然在继续正常执行，依然能够从文件中正确的读取内容。这是因为，rm 操作只是将 i_nlink 置为 0 了；由于文件被进程引用的缘故，`i_count` 不为 0，所以系统没有真正删除这个文件。i_nlink 是文件删除的充分条件，而 `i_count` 才是文件删除的必要条件。

基于以上只是，大家猜一下，如果在一个进程在打开文件写日志的时候，手动或者另外一个进程将这个日志删除，会发生什么情况？

是的，数据库并没有停掉。虽然日志文件被删除了，但是有一个进程已经打开了那个文件，所以向那个文件中的写操作仍然会成功，数据仍然会提交。

### 习题

Linux下两个进程可以同时打开同一个文件，这时如下描述**错误**的是(答案是4)：

1. 两个进程中分别产生生成两个独立的fd
2. 两个进程可以任意对文件进行读写操作，操作系统并不保证写的原子性
3. 进程可以通过系统调用对文件加锁，从而实现对文件内容的保护
4. 任何一个进程删除该文件时，另外一个进程会立即出现读写失败
5. 两个进程可以分别读取文件的不同部分而不会相互影响
6. 一个进程对文件长度和内容的修改另外一个进程可以立即感知


# Linux进程管理

## 创建守护进程的步骤

(两fork一set, u工文dev)
最关键的三步骤:

1. 调用fork，然后使父进程exit。
虽然子进程继承了父进程的进程组ID，但获得了一个新的进程ID，这就保证了子进程不是一个进程组的组长进程。这是下面将要进行的setsid调用的先决条件。

2. 调用setsid创建一个新会话。
使调用进程：(a)成为新会话的首进程，(b)成为一个新进程组的组长进程．(c)没有控制终端。也可概括为 : 开启一个新会话并释放它与控制终端之间的所有关联关系

3. 再次fork并杀掉首进程.
这样就确保了子进程不是一个会话首进程， 根据linux中获取终端的规则（只有会话首进程才能请求一个控制终端）， 这样进程永远不会重新请求一个控制终端


```
                   会      话
                 /     |      \
               /       |       \
             /         |         \
     前台进程组     后台进程组1     后台进程组2 ...
   /    |   \     /    |   \      /    |   \
进程1 进程2 ...  进程3 进程4 ...       ...
```

## 进程组

进程组就是一系列相互关联的进程集合，系统中的每一个进程也必须从属于某一个进程组；每个进程组中都会有一个唯一的 ID(process group id)，简称 PGID；PGID 一般等同于进程组的创建进程的 Process ID，而这个进进程一般也会被称为进程组先导 (process group leader)


## 会话

会话（session）是一个若干进程组的集合，同样的，系统中每一个进程组也都必须从属于某一个会话；一个会话只拥有最多一个控制终端（也可以没有），该终端为会话中所有进程组中的进程所共用。一个会话中前台进程组只会有一个，只有其中的进程才可以和控制终端进行交互；除了前台进程组外的进程组，都是后台进程组；和进程组先导类似，会话中也有会话先导 (session leader) 的概念，用来表示建立起到控制终端连接的进程。在拥有控制终端的会话中，session leader 也被称为控制进程(controlling process)，一般来说控制进程也就是登入系统的 shell 进程(login shell)；


## 杀死进程组或会话中的所有进程

我们可以使用该 PGID，通过 kill 命令向整个进程组发送信号：

`kill -SIGTERM -- -19701`

我们用一个负数 -19701 向进程组发送信号。如果我们传递的是一个正数，这个数将被视为进程 ID 用于终止进程。如果我们传递的是一个负数，它被视为 PGID，用于终止整个进程组。
负数来自系统调用的直接定义。

杀死会话中的所有进程与之完全不同。有些系统没有会话 ID 的概念。即使是具有会话 ID 的系统，例如 Linux，也没有提供系统调用来终止会话中的所有进程。你需要遍历 /proc 输出的进程树，收集所有的 SID，然后一一终止进程。
Pgrep 实现了遍历、收集并通过会话 ID 杀死进程的算法。使用以下命令：

`pkill -s <SID>`


## SIGHUP

SIGHUP 会在以下 3 种情况下被发送给相应的进程：

- 终端关闭时，该信号被发送到 session 首进程以及作为 job 提交的进程（即用 & 符号提交的进程）；
- session 首进程退出时，该信号被发送到该 session 中的前台进程组中的每一个进程；
- 若父进程退出导致进程组成为孤儿进程组，且该进程组中有进程处于停止状态（收到 SIGSTOP 或 SIGTSTP 信号），该信号会被发送到该进程组中的每一个进程。

例如：在我们登录 Linux 时，系统会分配给登录用户一个终端 (Session)。在这个终端运行的所有程序，包括前台进程组和后台进程组，一般都属于这个 Session。当用户退出 Linux 登录时，前台进程组和后台有对终端输出的进程将会收到 SIGHUP 信号。这个信号的默认操作为终止进程，因此前台进 程组和后台有终端输出的进程就会中止。
此外，对于与终端脱离关系的守护进程，正常情况下是永远都收不到这个信号的, 所以可以人为的发SIGHUP信号给她用于通知它做一些想要的自定义的操作, 比较常见的如重新读取配置文件操作。 比如 xinetd 超级服务程序。


## SIGCHLD与僵死进程

SIGCHLD信号,子进程结束时, 父进程会收到这个信号。如果父进程没有处理这个信号，也没有等待(waitpid)子进程，子进程虽然终止，但是还会在内核进程表中占有表项，这时的子进程称为僵尸进程。这种情 况我们应该捕捉它，或者wait它派生的子进程，或者父进程先终止，这时子进程的终止自动由init进程 来接管


## SIGPIPE

在网络编程中，SIGPIPE 这个信号是很常见的。当往一个写端关闭的管道或 socket 连接中连续写入数据时会引发 SIGPIPE 信号, 引发 SIGPIPE 信号的写操作将设置 errno 为 EPIPE。在 TCP 通信中，当通信的双方中的一方 close 一个连接时，若另一方接着发数据，根据 TCP 协议的规定，会收到一个 RST 响应报文，若再往这个服务器发送数据时，系统会发出一个 SIGPIPE 信号给进程，告诉进程这个连接已经断开了，不能再写入数据。

因为 SIGPIPE 信号的默认行为是结束进程，而我们绝对不希望因为写操作的错误而导致程序退出，尤其是作为服务器程序来说就更恶劣了。所以我们应该对这种信号加以处理，在这里，介绍处理 SIGPIPE 信号的方式：

一般给 SIGPIPE 设置 SIG_IGN 信号处理函数，忽略该信号:

`signal(SIGPIPE, SIG_IGN);`

前文说过，引发 SIGPIPE 信号的写操作将设置 errno 为 EPIPE,。所以，第二次往关闭的 socket 中写入数据时, 会返回 - 1, 同时 errno 置为 EPIPE. 这样，便能知道对端已经关闭，然后进行相应处理，而不会导致整个进程退出.


# TCP

包头长度 20个字节

## 三次握手

``` puml
rnote over A : CLOSED
rnote over B : LISTEN
A -> B : SYN=1, seq=x
rnote over A : SYN_SENT
rnote over B : SYN_RECV
A <- B : SYN=1, ACK=x+1, seq=y
rnote over A : SYN_SENT
rnote over B : SYN_RECV
A -> B : ACK=y+1
rnote over A : ESTABLISHED
rnote over B : ESTABLISHED
```

### 如果第三次握手的ack丢失了咋办

当客户端收到服务端的SYNACK应答后，其状态变为ESTABLISHED，并会发送ACK包给服务端，准备发送数据了。如果此时ACK在网络中丢失（如上图所示），过了超时计时器后，那么服务端会重新发送SYNACK包，重传次数根据/proc/sys/net/ipv4/tcp_synack_retries来指定，默认是5次。如果重传指定次数到了后，仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。

问题就在这里，客户端已经认为连接建立，而服务端则可能处在SYN-RCVD或者CLOSED，接下来我们需要考虑这两种情况下服务端的应答：

* 服务端处于CLOSED，当接收到连接已经关闭的请求时，服务端会返回RST 报文，客户端接收到后就会关闭连接，如果需要的话则会重连，那么那就是另一个三次握手了。
* 服务端处于SYN-RCVD，此时如果接收到正常的ACK 报文，那么很好，连接恢复，继续传输数据；如果接收到写入数据等请求呢？注意了，此时写入数据等请求也是带着ACK 报文的，实际上也能恢复连接，使服务器恢复到ESTABLISHED状态，继续传输数据。


### 知道SYN攻击吗？如何防范？

所谓SYN 洪泛攻击，就是利用SYNACK 报文的时候，服务器会为客户端请求分配缓存，那么黑客（攻击者），就可以使用一批虚假的ip向服务器大量地发建立TCP 连接的请求，服务器为这些虚假ip分配了缓存后，处在SYN_RCVD状态，存放在半连接队列中；另外，服务器发送的请求又不可能得到回复（ip都是假的，能回复就有鬼了），只能不断地重发请求，直到达到设定的时间/次数后，才会关闭。

服务器不断为这些半开连接分配资源，导致服务器的连接资源被消耗殆尽，不过所幸，我们可以使用SYN Cookie进行稍微的防御一下。

所谓的SYN Cookie防御系统，与前面接收到SYN 报文就分配缓存不同，此时暂不分配资源；同时利用SYN 报文的源和目的地IP和端口，以及服务器存储的一个秘密数，使用它们进行散列，得到server_isn，然后附着在SYNACK 报文中发送给客户端，接下来就是对ACK 报文进行判断，如果其返回的ack字段正好等于server_isn + 1，说明这是一个合法的ACK，那么服务器才会为其生成一个具有套接字的全开的连接。(有点类似于[JWT](#JWT)那一套机制哈)

缺点: 
* 增加了密码学运算, 增大了cpu消耗
* 因为没有保存半连接状态, 所以无法存储一些比如大窗口/sack等信息


## 四次挥手

```puml
rnote over A : ESTABLISHED
rnote over B : ESTABLISHED
A -> B : FIN=1, seq=x
rnote over A : FIN_WAIT1
rnote over B : CLOSE_WAIT
A <- B : ACK=x+1
rnote over B : CLOSE_WAIT
rnote over A : FIN_WAIT2
A <- B : FIN=1, seq=y
rnote over A : TIME_WAIT
rnote over B : LAST_ACK
A -> B : ACK=y+1
rnote over B : CLOSED
rnote over A : 等待2MSL ...
rnote over A : CLOSED
```

### timewait的意义

- 2msl之后网络中的数据分节全部消失, 防止影响到复用了原端口ip的新连接
- 如果b没收到最后一个ack, b就会重发fin, a如果不维护一个timewait却收到了一个fin会感觉莫名其妙然后响应一个rst, 然后b就会解释为一个错误


## tcp拥塞控制

- 快速重传: 
    报文段1成功接收并被确认ACK 2，接收端的期待序号为2，当报文段2丢失，报文段3失序到来，与接收端的期望不匹配，接收端重复发送冗余ACK 2。这样，如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK（其实是收到4个同样的ACK，第一个是正常的，后三个才是冗余的），发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出，大大提高了效率。这便是快速重传机制。

- 快速恢复
- 慢启动
- 拥塞避免

![](/img/noodle_plan/tcp/tcp_congestion_control.png)


## tcp滑动窗口

![](/img/noodle_plan/tcp/tcp_sliding_window1.png)

每个TCP连接的两端都维护一组窗口：发送窗口结构（send window structure）和接收窗口结构（receive window structure）。TCP以字节为单位维护其窗口结构。TCP头部中的窗口大小字段相对ACK号有一个字节的偏移量。发送端计算其可用窗口，即它可以立即发送的数据量。可用窗口（允许发送但还未发送）计算值为提供窗口（即由接收端通告的窗口）大小减去在传（已发送但未得到确认）的数据量。图中P1、P2、P3分别记录了窗口的左边界、下次发送的序列号、右边界。

![](/img/noodle_plan/tcp/tcp_sliding_window2.png)

如上图所示， 随着发送端接收到返回的数据ACK，滑动窗口也随之右移。发送端根据接收端返回的ACK可以得到两个重要的信息：一是接收端期望收到的下一个字节序号；二是当前的窗口大小（再结合发送端已有的其他信息可以得出还能发送多少字节数据）。

需要注意的是：发送窗口的左边界只能右移，因为它控制的是已发送并受到确认的数据，具有累积性，不能返回；右边界可以右移也可以左移（能左移的右边界会带来一些缺陷，下文会讲到）。

接收端也维护一个窗口结构，但比发送窗口简单（只有左边界和右边界）。该窗口结构记录了已接收并确认的数据，以及它能够接收的最大序列号，该窗口能保证接收数据的正确性（避免存储重复的已接收和确认的数据，以及避免存储不应接收的数据）。由于TCP的累积ACK特性，只有当到达数据序列号等于左边界时，窗口才能向前滑动。


### 零窗口与TCP持续计时器

当窗口的左右边界重合（即窗口大小为0）时，发送端将停止发送数据直到窗口大小恢复为非零值，这样的窗口称为零窗口。当接收端重新获得可用空间，会给发送端发送一个窗口更新（window update），告知其可以继续发送数据。这样的窗口更新通常不包含数据（为纯ACK）。

但接收端发送的窗口更新是ACK报文，不能保证传输的可靠性。因此如果一个包含窗口更新的ACK丢失，通信双方就会一直处于等待状态：接收方等待接收数据（它已经发送了窗口更新），发送方等待窗口更新告知其可以继续发送，这样就会陷入死锁状态。为避免死锁发生，发送端会采用一个持续计时器间歇性地询问接收端，看其窗口是否增长。持续窗口计时器会触发窗口探测（window probe）消息的发送，强制要求接收端返回ACK。窗口探测包含一个字节的数据，采用TCP可靠传输（重传），强制要求接收端返回ACK，因此可以避免因窗口更新丢失而导致的死锁。


## ACK延迟确认机制

接收方在收到数据后，并不会立即回复ACK,而是延迟一定时间。一般ACK延迟发送的时间为200ms，但这个200ms并非收到数据后需要延迟的时间。系统有一个固定的定时器每隔200ms会来检查是否需要发送ACK包。这样做有两个目的。
1. 这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。
2. 如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。


# MySQL


## 重点参考博客截图

- [通过面试题学MySQL基础篇](html_screen_shot/mysql/通过面试题学MySQL基础篇.png)
- [通过面试题学MySQL进阶篇](html_screen_shot/mysql/通过面试题学MySQL进阶篇.png)
- [后端程序员必备：索引失效的十大杂症](html_screen_shot/mysql/后端程序员必备：索引失效的十大杂症.png)
- [MySQL_InnoDB_ MVCC机制的原理及实现](html_screen_shot/mysql/MySQL_InnoDB_MVCC机制的原理及实现.png)
- [MySQL的redo log、undo log、binlog](html_screen_shot/mysql/MySQL的redo%20log、undo%20log、binlog.png)
- [MySQL的redo log、undo log、binlog_简书](html_screen_shot/mysql/MySQL的redo%20log、undo%20log、binlog_简书.png)


## 参考网址

- https://chenjiabing666.github.io/2020/04/20/Mysql%E6%9C%80%E5%85%A8%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8D%97/
- https://blog.csdn.net/qq_41011723/article/details/105953813
- https://blog.csdn.net/qq_41011723/article/details/106028153


## redo log与binlog与undo log的区别

参考 https://www.cnblogs.com/Java3y/p/12453755.html , 写的非常好

也可参考 https://www.jianshu.com/p/68d5557c65be


### redo log

redo log 存在于InnoDB 引擎中，InnoDB引擎是以插件形式引入Mysql的，redo log的引入主要是为了实现Mysql的crash-safe能力。

实际上Mysql的基本存储结构是页(记录都存在页里边)，所以MySQL是先把这条记录所在的页找到，然后把该页加载到内存中，将对应记录进行修改。

现在就可能存在一个问题：如果在内存中把数据改了，还没来得及落磁盘，而此时的数据库挂了怎么办？显然这次更改就丢了。

如果每个请求都需要将数据立马落磁盘之后，那速度会很慢，MySQL可能也顶不住。所以MySQL是怎么做的呢？
MySQL引入了redo log，内存写完了，然后会写一份redo log，这份redo log记载着这次在某个页上做了什么修改。
其实写redo log的时候，也会有buffer，是先写buffer，再真正落到磁盘中的。至于从buffer什么时候落磁盘，会有配置供我们配置。

写redo log也是需要写磁盘的，但它的好处就是顺序IO（我们都知道顺序IO比随机IO快非常多）。

所以，redo log的存在为了：当我们修改的时候，写完内存了，但数据还没真正写到磁盘的时候。此时我们的数据库挂了，我们可以根据redo log来对数据进行恢复。因为redo log是顺序IO，所以写入的速度很快，并且redo log记载的是物理变化（xxxx页做了xxx修改），文件的体积很小，恢复速度很快


### binlog

binlog记录了数据库表结构和表数据变更，比如update/delete/insert/truncate/create。它不会记录select（因为这没有对表没有进行变更）

binlog长什么样？

binlog我们可以简单理解为：存储着每条变更的SQL语句

而redo log 保证的是数据库的 crash-safe 能力。采用的策略就是常说的“两阶段提交”。

一条update的SQL语句是按照这样的流程来执行的：

将数据页加载到内存 → 修改数据 → 更新数据 → 写redo log（状态为prepare） → 写binlog → 提交事务（数据写入成功后将redo log状态改为commit）

只有当两个日志都提交成功（刷入磁盘），事务才算真正的完成。

一旦发生系统故障（不管是宕机、断电、重启等等），都可以配套使用 redo log 与 binlog 做数据修复。


### undo log

undo log有什么用？

undo log主要有两个作用：回滚和多版本控制(MVCC)

在数据修改的时候，不仅记录了redo log，还记录undo log，如果因为某些原因导致事务失败或回滚了，可以用undo log进行回滚

undo log主要存储的也是逻辑日志，比如我们要insert一条数据了，那undo log会记录的一条对应的delete日志。我们要update一条记录时，它会记录一条对应相反的update记录。

这也应该容易理解，毕竟回滚嘛，跟需要修改的操作相反就好，这样就能达到回滚的目的。因为支持回滚操作，所以我们就能保证：“一个事务包含多个操作，这些操作要么全部执行，要么全都不执行”。【原子性】

因为undo log存储着修改之前的数据，相当于一个前版本，MVCC实现的是读写不阻塞，读的时候只要返回前一个版本的数据就行了。


### undolog和binlog和redolog不同之处总结

  - 参考 https://www.jianshu.com/p/68d5557c65be
  - redo log
     物理格式的日志，记录的是物理数据页面的修改的信息（数据库中每个页的修改），面向的是表空间、数据文件、数据页、偏移量等。
  - undo log
     逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，与redo log不同。
  - binlog
     逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
     但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息。比如delete操作的话，就对应着delete本身和其反向的insert；update操作的话，就对应着update执行前后的版本的信息；insert操作则对应着delete和insert本身的信息。
     因此可以基于binlog做到闪回功能。
  - binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用。
  - redo log是在InnoDB存储引擎层产生，而binlog是MySQL数据库的上层产生的，并且binlog日志不仅仅针对INNODB存储引擎，MySQL数据库中的任何存储引擎对于数据库的更改都会产生binlog日志。
  - 两种日志记录的内容形式不同。MySQL的binlog是逻辑日志，可以简单认为记录的就是sql语句。而innodb存储引擎层面的redo日志是物理日志, 是数据页面的修改之后的物理记录。
  - 关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。因此redo日志的写盘，并不一定是随着事务的提交才写入redo日志文件的，而是随着事务的开始，逐步开始的。那么当我执行一条 update 语句时，redo log 和 binlog 是在什么时候被写入的呢？这就有了我们常说的「两阶段提交」：
    - 写入：redo log（prepare）
    - 写入：binlog
    - 写入：redo log（commit）
  - 两种日志与记录写入磁盘的时间点不同，binlog日志只在事务提交完成后进行一次写入。而innodb存储引擎的redo日志在事务进行中不断地被写入，并日志不是随事务提交的顺序进行写入的。
  - binlog日志仅在事务提交时记录，并且对于每一个事务，仅在事务提交时记录，并且对于每一个事务，仅包含对应事务的一个日志。而对于innodb存储引擎的redo日志，由于其记录是物理操作日志，因此每个事务对应多个日志条目，并且事务的redo日志写入是并发的，并非在事务提交时写入，其在文件中记录的顺序并非是事务开始的顺序。
  - binlog不是循环使用，在写满或者重启之后，会生成新的binlog文件，redo log是循环使用。
- binlog 日志是 master 推的还是 salve 来拉的？
  slave来拉的, 因为每一个slave都是完全独立的个体，所以slave完全依据自己的节奏去处理同步，


## 主从同步延迟与同步数据丢失问题

主库将变更写binlog日志，然后从库连接到主库之后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个中继日志中。接着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容，也就是在自己本地再次执行一遍SQL，这样就可以保证自己跟主库的数据是一样的。

这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行SQL的特点，在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。

而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。

所以mysql实际上在这一块有两个机制，一个是半同步复制，用来解决主库数据丢失问题；一个是并行复制，用来解决主从同步延时问题(实在解决不了只能强制读主库)。


### 半同步复制

这个所谓半同步复制，semi-sync复制，指的就是主库写入binlog日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的relay log之后，接着会返回一个ack给主库，主库接收到至少一个从库的ack之后才会认为写操作完成了。


### 并行复制
所谓并行复制，指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。


## 二阶段提交

 redo log 保证的是数据库的 crash-safe 能力。采用的策略就是常说的“两阶段提交”。

 一条update的SQL语句是按照这样的流程来执行的：

 将数据页加载到内存 → 修改数据 → 更新数据 → 写redo log（状态为prepare） → 写binlog → 提交事务（数据写入成功后将redo log状态改为commit）

 只有当两个日志都提交成功（刷入磁盘），事务才算真正的完成。

 一旦发生系统故障（不管是宕机、断电、重启等等），都可以配套使用 redo log 与 binlog 做数据修复。

### 两阶段提交机制的必要性

binlog 存在于Mysql Server层中，主要用于数据恢复；当数据被误删时，可以通过上一次的全量备份数据加上某段时间的binlog将数据恢复到指定的某个时间点的数据。
redo log 存在于InnoDB 引擎中，InnoDB引擎是以插件形式引入Mysql的，redo log的引入主要是为了实现Mysql的crash-safe能力。

假设redo log和binlog分别提交，可能会造成用日志恢复出来的数据和原来数据不一致的情况。

1）假设先写redo log再写binlog，即redo log没有prepare阶段，写完直接置为commit状态，然后再写binlog。那么如果写完redo log后Mysql宕机了，重启后系统自动用redo log 恢复出来的数据就会比
binlog记录的数据多出一些数据，这就会造成磁盘上数据库数据页和binlog的不一致，下次需要用到
binlog恢复误删的数据时，就会发现恢复后的数据和原来的数据不一致。
2）假设先写binlog再写redolog。如果写完redo log后Mysql宕机了，那么binlog上的记录就会比磁盘上数据页的记录多出一些数据出来，下次用binlog恢复数据，就会发现恢复后的数据和原来的数据不一致。

由此可见，redo log和binlog的两阶段提交是非常必要的。


## 索引

- 聚集索引是啥
  - 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据
  - 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。
  
- 外键是啥: 比如在students表中，通过class_id的字段，可以把数据与另一张表关联起来，这种列称为外键(一般不用外键, 因为会降低数据库性能)

- mysql 索引在什么情况下会失效
  - https://database.51cto.com/art/201912/607742.htm
  - 查询条件包含or，可能导致索引失效
  - 如何字段类型是字符串，where时一定用引号括起来，否则索引失效
  - like通配符可能导致索引失效。
  - 联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。
  - 在索引列上使用mysql的内置函数，索引失效
  - 对索引列运算（如，+、-、*、/），索引失效。
  - 索引字段上使用（！= 或者 < >，not in）时，可能会导致索引失效。
  - 索引字段上使用is null， is not null，可能导致索引失效。
  - 左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。
  - mysql估计使用全表扫描要比使用索引快,则不使用索引。

- mysql 的索引模型:
  在MySQL中使用较多的索引有Hash索引，B+树索引等，而我们经常使用的InnoDB存储引擎的默认索引实现为：B+树索引。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。


## mysql 有那些存储引擎，有哪些区别

1. MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持。
2. MyISAM类型的表强调的是性能，其执行速度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持以及外部键等高级数据库功能。
3. 现在一般都是选用InnoDB了，InnoDB支持行锁, 而MyISAM的全表锁，myisam的读写串行问题，并发效率锁表，效率低，MyISAM对于读写密集型应用一般是不会去选用的
4. memory引擎一般用于临时表, 使用表级锁，没有事务机制, 虽然内存访问快，但如果频繁的读写，表级锁会成为瓶颈, 且内存昂贵..满了就亏了
5. InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。


## mysql 主从同步分哪几个过程

- ![](/img/noodle_plan/mysql/mysql_master_slave_sync.jpg)
- 复制的基本过程如下：
 1. 从节点上的I/O 线程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；
 2. 主节点接收到来自从节点的I/O请求后，通过负责复制的I/O线程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log file 的以及bin-log position；从节点的I/O线程接收到内容后，将接收到的日志内容更新到本机的relay log中，并将读取到的binary log文件名和位置保存到master-info 文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；
 3. Slave 的 SQL线程检测到relay-log 中新增加了内容后，会将relay-log的内容解析成在主节点上实际执行过的操作，并在本数据库中执行。

## 乐观锁与悲观锁的区别？

- 悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于数据更新比较频繁的场景；
- 乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于读多写少的场景。

## mvcc是啥

- MVCC (Multiversion Concurrency Control) 中文全程叫多版本并发控制，是现代数据库（包括 MySQL、Oracle、PostgreSQL 等）引擎实现中常用的处理读写冲突的手段，目的在于提高数据库高并发场景下的吞吐性能。
- 如此一来不同的事务在并发过程中，SELECT 操作可以不加锁而是通过 MVCC 机制读取指定的版本历史记录，并通过一些手段保证保证读取的记录值符合事务所处的隔离级别，从而解决并发场景下的读写冲突。
- https://chenjiayang.me/2019/06/22/mysql-innodb-mvcc/


## 实现事务采取了哪些技术以及思想？

* ★ a原子性：使用 undo log ，从而达到回滚
* ★ d持久性：使用 redo log，从而达到故障后恢复
* ★ i隔离性：使用锁以及MVCC,运用的优化思想有读写分离，读读并行，读写并行
* ★ c一致性：通过回滚，以及恢复，和在并发环境下的隔离做到一致性。


## mysql四个隔离级别

四个隔离级别的区别以及每个级别可能产生的问题以及实现原理: https://developer.aliyun.com/article/743691

MySQL的事务隔离级别一共有四个，分别是

* 读未提交
* 读已提交
* 可重复读
* 可串行化。

MySQL的隔离级别的作用就是让事务之间互相隔离，互不影响，这样可以保证事务的一致性。

隔离级别比较：可串行化>可重复读>读已提交>读未提交

隔离级别对性能的影响比较：可串行化>可重复读>读已提交>读未提交

由此看出，隔离级别越高，所需要消耗的MySQL性能越大（如事务并发严重性），为了平衡二者，一般建议设置的隔离级别为可重复读，MySQL默认的隔离级别也是可重复读。

### 事务并发可能出现的情况

* 脏读（Dirty Read）
  一个事务读到了另一个未提交事务修改过的数据

  从根上理解MySQL事务的隔离级别

  会话B开启一个事务，把id=1的name为武汉市修改成温州市，此时另外一个会话A也开启一个事务，读取id=1的name，此时的查询结果为温州市，会话B的事务最后回滚了刚才修改的记录，这样会话A读到的数据是不存在的，这个现象就是脏读。（脏读只在读未提交隔离级别才会出现）

* 不可重复读（Non-Repeatable Read）
  一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值。（不可重复读在读未提交和读已提交隔离级别都可能会出现）

  从根上理解 MySQL 事务的隔离级别

  会话A开启一个事务，查询id=1的结果，此时查询的结果name为武汉市。接着会话B把id=1的name修改为温州市（隐式事务，因为此时的autocommit为1，每条SQL语句执行完自动提交），此时会话A的事务再一次查询id=1的结果，读取的结果name为温州市。会话B再此修改id=1的name为杭州市，会话A的事务再次查询id=1，结果name的值为杭州市，这种现象就是不可重复读。

* 幻读（Phantom）
  一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。（幻读在读未提交、读已提交、可重复读隔离级别都可能会出现）

  从根上理解 MySQL 事务的隔离级别

  会话A开启一个事务，查询id>0的记录，此时会查到name=武汉市的记录。接着会话B插入一条name=温州市的数据（隐式事务，因为此时的autocommit为1，每条SQL语句执行完自动提交），这时会话A的事务再以刚才的查询条件（id>0）再一次查询，此时会出现两条记录（name为武汉市和温州市的记录），这种现象就是幻读。


### 各个隔离级别的详细说明

* 读未提交（READ UNCOMMITTED）
  在读未提交隔离级别下，事务A可以读取到事务B修改过但未提交的数据。

  可能发生脏读、不可重复读和幻读问题，一般很少使用此隔离级别。

* 读已提交（READ COMMITTED）
  在读已提交隔离级别下，事务B只能在事务A修改过并且已提交后才能读取到事务B修改的数据。

  读已提交隔离级别解决了脏读的问题，但可能发生不可重复读和幻读问题，一般很少使用此隔离级别。

* 可重复读（REPEATABLE READ）
  在可重复读隔离级别下，事务B只能在事务A修改过数据并提交后，自己也提交事务后，才能读取到事务B修改的数据。

  可重复读隔离级别解决了脏读和不可重复读的问题，但可能发生幻读问题。

  提问：为什么上了写锁（写操作），别的事务还可以读操作？

  因为InnoDB有MVCC机制（多版本并发控制），可以使用快照读，而不会被阻塞。

* 可串行化（SERIALIZABLE）
  各种问题（脏读、不可重复读、幻读）都不会发生，通过加锁实现（读锁和写锁）。


### 隔离级别的实现原理

使用MySQL的默认隔离级别（可重复读）来进行说明。

每条记录在更新的时候都会同时记录一条回滚操作（回滚操作日志undo log）。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。即通过回滚（rollback操作），可以回到前一个状态的值。InnoDB 为了解决这个问题，设计了 ReadView（可读视图）的概念.


# Redis

## 重点参考博客截图

- [通过面试题学Redis--基础篇](html_screen_shot/redis/通过面试题学Redis--基础篇.png)
- [通过面试题学Redis--进阶篇](html_screen_shot/redis/通过面试题学Redis--进阶篇.png)
- [压缩列表](html_screen_shot/redis/压缩列表.png)
- [有序集zset](html_screen_shot/redis/有序集zset.png)
- [zset](html_screen_shot/redis/zset.png)


## redis 数据结构有哪些？分别怎么实现的？

* String: 全是整数的时候用`整数编码int`, 当有字符串的时候用`简单动态字符串sds`编码
* HashTable: 元素比较少或者元素比较短的时候用`压缩表ziplist`(key1|val1|key2|val2|...这样存储), 其他时候就用`字典ht`
* Set: 元素全是整数的时候用`整数集合`编码(一种特殊的编码, 会使用各种规则来利用位空间, 来节省内存), 其他时候用`字典ht`编码(键为Set的元素, 值都为Null)
* List: 元素比较少或者元素比较短的时候用`压缩表ziplist`, 其他时候就用`双端列表LinkedList`编码
* ZSet: 元素比较少或者元素比较短的时候用`压缩表ziplist`(member1|score1|member2|score2|..., 按照score从小到大排列), 其他时候就用`跳跃表SkipList编码`(这个编码里包含一个字典结构和一个跳表结构, 字典用于快速查找member如`ZScore`指令的score和确定是否有这个member, 跳表用于`zrank`/`zrange`等)

## 延时队列用redis怎么做

用zset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者轮询zset用zrangebyscore指令获取N秒之前的数据轮询进行处理。

## Redis 的 ZSET 做排行榜时，如果要实现分数相同时按时间顺序排序怎么实现

说了一个将 score 拆成高 32 位和低 32 位，高 32 位存分数，低 32 位存时间的方法。问还有没有其他方法，想不出了


## 有序集合的实现

  - 参考 http://redisbook.com/preview/object/sorted_set.html
  - 参考 https://redisbook.readthedocs.io/en/latest/datatype/sorted_set.html
  - https://blog.csdn.net/qq_41011723/article/details/105922185
  - https://redisbook.readthedocs.io/en/latest/compress-datastruct/ziplist.html
  - https://blog.csdn.net/qq_41011723/article/details/105937216
  - **编码选择规则**:
   在通过 ZADD 命令添加第一个元素到空 key 时， 程序通过检查输入的第一个元素来决定该创建什么编码的有序集。
    如果第一个元素符合以下条件的话， 就创建一个 `REDIS_ENCODING_ZIPLIST` 编码的有序集：
    - 服务器属性 server.zset_max_ziplist_entries 的值大于 0 （默认为 128 ）。
    - 元素的 member 长度小于服务器属性 server.zset_max_ziplist_value 的值（默认为 64 ）。

    否则，程序就创建一个 `REDIS_ENCODING_SKIPLIST` 编码的有序集。
    当后续有元素不满足上述两个条件的时候, 有序集合对象将转为使用 `REDIS_ENCODING_SKIPLIST` 编码.

    通俗的说就是:
      - `REDIS_ENCODING_ZIPLIST`(压缩列表ziplist): 少量成员项member, 且member的长度较短(比如是小整数或是短字符串), 那么 Redis 就会使用压缩列表来做列表键的底层实现。
      - `REDIS_ENCODING_SKIPLIST`(跳表skiplist+字典): 如果一个有序集合包含的元素数量比较多， 又或者有序集合中元素的成员（member）是比较长的字符串时， Redis 就会使用跳跃表来作为有序集合键的底层实现。
  - **`REDIS_ENCODING_SKIPLIST` 编码详解**:
    - 当使用 `REDIS_ENCODING_SKIPLIST` 编码时， 有序集元素由 redis.h/zset 结构体来保存, 而zset结构体包含 **跳表**+**字典**
    - 通过使用字典结构， 并将 member 作为键， score 作为值， 有序集可以在 O(1) 复杂度内：
      - 检查给定 member 是否存在于有序集（被很多底层函数使用）；
      - 取出 member 对应的 score 值（实现 ZSCORE 命令）。
    - 通过使用跳跃表， 可以让有序集支持以下两种操作：
      - 在 O(logN) 期望时间、 O(N) 最坏时间内根据 score 对 member 进行定位（被很多底层函数使用）；
      - 范围性查找和处理操作，这是（高效地）实现 ZRANGE 、 ZRANK 和 ZINTERSTORE 等命令的关键。
    - 所以通过同时使用字典和跳跃表， 有序集可以高效地实现按成员查找和按顺序查找两种操作。

## redis 持久化有哪几种方式，怎么选？

- 混合持久化
  重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。
  如果使用 AOF 日志重放，性能则相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动的时候需要花费很长的时间。
  Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。
  混合持久化同样也是通过bgrewriteaof完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以RDB方式写入aof文件，然后在将aof_rewrite_buf重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。简单的说：新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据，
- rdb
  - 优势: 
    - RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。
    - 生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。
    - RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。
  - 劣势:
    - 当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。
- aof
  - 优势: 
    - AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个**后台刷盘线程**执行一次fsync操作(这种一秒刷盘一次的策略, 可能会造成**追加阻塞**: 当硬盘资源繁忙时，即主线程发现距离上次fsync时间超过2秒, 为了数据安全性, 主线程会阻塞直到后台刷盘线程执行fsync操作完成)，最多丢失1秒钟的数据。所以这也是redis重启优先加载aof的理由
    - AOF日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。
    - AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。
    - AOF日志文件的命令通过可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据
  - 劣势:
    - 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大
    - AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的


### bgsave流程说一下

![](/img/noodle_plan/redis/bgsave.png)

子进程创建RDB文件, 根据父进程内存生成临时快照文件, 完成后对原有RDB文件进行源自替换. 然后子进程发送信号给父进程表示完成


### aof流程说一下以及aof追加阻塞是啥

![](/img/noodle_plan/redis/aof.png)

追加阻塞: 

当开启 AOF 持久化时，常用的同步硬盘的策略是“每秒同步” everysec，用于平衡性能和数据安全性，对于这种方式，redis 使用另一条线程每秒执行 fsync 同步硬盘，当硬盘资源繁忙时，将造成 Redis 主线程阻塞。


### AOF重写的实现

所谓的“重写”其实是一个有歧义的词语， 实际上， AOF 重写并不需要对原有的 AOF 文件进行任何写入和读取， 它针对的是数据库中键的当前值。

AOF 重写程序可以很好地完成创建一个新 AOF 文件的任务， 但是， 在执行这个程序的时候， 调用者线程会被阻塞。

很明显， 作为一种辅佐性的维护手段， Redis 不希望 AOF 重写造成服务器无法处理请求， 所以 Redis 决定将 AOF 重写程序放到（后台）子进程里执行， 这样处理的最大好处是：

* 子进程进行 AOF 重写期间，主进程可以继续处理命令请求。
* 子进程带有主进程的数据副本，使用子进程而不是线程，可以在避免锁的情况下，保证数据的安全性。

不过， 使用子进程也有一个问题需要解决： 因为子进程在进行 AOF 重写期间， 主进程还需要继续处理命令， 而新的命令可能对现有的数据进行修改， 这会让当前数据库的数据和重写后的 AOF 文件中的数据不一致。

为了解决这个问题， Redis 增加了一个 AOF 重写缓存， 这个缓存在 fork 出子进程之后开始启用， Redis 主进程在接到新的写命令之后， 除了会将这个写命令的协议内容追加到现有的 AOF 文件之外， 还会追加到这个缓存中：

换言之， 当子进程在执行 AOF 重写时， 主进程需要执行以下三个工作：

1. 处理命令请求。
2. 将写命令追加到现有的 AOF 文件中。
3. 将写命令追加到 AOF 重写缓存中。
这样一来可以保证：

1. 现有的 AOF 功能会继续执行，即使在 AOF 重写期间发生停机，也不会有任何数据丢失。
2. 所有对数据库进行修改的命令都会被记录到 AOF 重写缓存中。

当子进程完成 AOF 重写之后， 它会向父进程发送一个完成信号， 父进程在接到完成信号之后， 会调用一个信号处理函数， 并完成以下工作：

1. 将 AOF 重写缓存中的内容全部写入到新 AOF 文件中。
2. 对新的 AOF 文件进行改名，覆盖原有的 AOF 文件。

当步骤 1 执行完毕之后， 现有 AOF 文件、新 AOF 文件和数据库三者的状态就完全一致了。

当步骤 2 执行完毕之后， 程序就完成了新旧两个 AOF 文件的交替。

这个信号处理函数执行完毕之后， 主进程就可以继续像往常一样接受命令请求了。 在整个 AOF 后台重写过程中， 只有最后的写入缓存和改名操作会造成主进程阻塞， 在其他时候， AOF 后台重写都不会对主进程造成阻塞， 这将 AOF 重写对性能造成的影响降到了最低。

以上就是 AOF 后台重写， 也即是 BGREWRITEAOF 命令的工作原理。


## redis 主从同步是怎样的过程？

1. 从redis发出sync要求
2. 主redis开始bgsave(并且一边开启指令buffer来存储bgsave过程中的写指令们记为`cmd`)
3. 主redis把bgsave生成的rdb发给从redis
4. 把`cmd`发送给从redis
5. 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令

**总结:**

主从刚刚连接的时候，进行全量同步；全量同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。



## redis key 的过期策略

Redis键的过期策略，是有定期删除+惰性删除两种。
* 定期好理解，默认100ms就 随机 抽一些设置了过期时间的key，去检查是否过期，过期了就删了。
* 惰性删除，查询时再判断是否过期，过期就删除键不返回值。


## 内存淘汰机制

当新增数据发现内存达到限制时，Redis触发内存淘汰机制。
- lru
- lfu(least frequency used, redis 4新增)
- random
- ttl


### redis的lru算法说一下

普通的lru算法一般是用哈希表+双向链表来实现的:

基于 HashMap 和 双向链表实现 LRU 的整体的设计思路是，可以使用 HashMap 存储 key，这样可以做到 save 和 get key的时间都是 O(1)，而 HashMap 的 Value 指向双向链表实现的 LRU 的 Node 节点. 其核心操作的步骤是:

* save(key, value)，首先在 HashMap 找到 Key 对应的节点，如果节点存在，更新节点的值，并把这个节点移动队头。如果不存在，需要构造新的节点，并且尝试把节点塞到队头，如果LRU空间不足，则通过 tail 淘汰掉队尾的节点，同时在 HashMap 中移除 Key。
* get(key)，通过 HashMap 找到 LRU 链表节点，因为根据LRU 原理，这个节点是最新访问的，所以要把节点插入到队头，然后返回缓存的值。

**Redis的LRU实现**:

如果按照HashMap和双向链表实现，需要额外的存储存放 next 和 prev 指针，牺牲比较大的存储空间，显然是不划算的。所以Redis采用了一个近似的做法，就是定时每隔一段时间就随机取出若干个key，然后按照访问时间排序后，淘汰掉最不经常使用的.

Redis 3.0之后又改善了算法的性能，会提供一个待淘汰候选key的pool，里面默认有16个key，按照空闲时间排好序。更新时从Redis键空间随机选择N个key，分别计算它们的空闲时间 idle，key只会在pool不满或者空闲时间大于pool里最小的时，才会进入pool，然后从pool中选择空闲时间最大的key淘汰掉。


## redis哨兵

1) Redis Sentinel是Redis的高可用实现方案：故障发现、故障自动转移、配置中心 客户端通知。 
2) Redis Sentinel从Redis 2.8版本开始才正式生产可用，之前版本生产不可用。 
3) 尽可能在不同物理机上部署Redis Sentinel所有节点。 
4) Redis Sentinel中的Sentinel节点个数应该为大于等于3且最好为奇数。
5) Redis Sentinel中的数据节点与普通数据节点没有区别。
6) 哨兵是一个配置提供者，而不是代理。在引入哨兵之后，客户端会先连接哨兵，再获取到主节点之后，客户端会和主节点直接通信。如果发生了故障转移，哨兵会通知到客户端。这也需要客户端对哨兵的显式支持。 
7) Redis Sentinel通过三个定时任务实现了Sentinel节点对于主节点、从节点、其余 Sentinel节点的监控。
8) Redis Sentinel在对节点做失败判定时分为主观下线和客观下线。
9) Redis Sentinel实现读写分离高可用可以依赖Sentinel节点的消息通知，获取Redis 数据节点的状态变化。 

用文字描述一下故障切换（failover）的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。然后通过**raft算法**从哨兵中选出一个leader来执行**故障转移**


## redis集群

集群模式
redis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过1000个节点)。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单。
集群模式有以下几个特点：

* 由多个Redis服务器组成的分布式网络服务集群；
* 集群之中有多个Master主节点，每一个主节点都可读可写；
* 节点之间会互相通信，两两相连, 采用gossip协议来通信；
* Redis集群无中心节点。
* 集群的伸缩本质是: 槽数据在节点中的移动

### 优点

在哨兵模式中，仍然只有一个Master节点。当并发写请求较大时，哨兵模式并不能缓解写压力。 我们知道只有主节点才具有写能力，那如果在一个集群中，能够配置多个主节点，缓解写压力，redis-cluster集群模式能达到此类要求。

在Redis-Cluster集群中，可以给每一个主节点添加从节点，主节点和从节点直接遵循主从模型的特性。
当用户需要处理更多读请求的时候，添加从节点开启read-only来读写分离可以扩展系统的读性能。

### 故障转移

Redis集群的主节点内置了类似Redis Sentinel的节点故障检测和自动故障转移功能，当集群中的某个主节点下线时，集群中的其他在线主节点会注意到这一点，并对已下线的主节点进行故障转移。
集群进行故障转移的方法和Redis Sentinel进行故障转移的方法基本一样(也有`主观下线`和`客观下线`)，不同的是，在集群里面，故障转移的过程是:

1. 在集群内广播选举消息
2. 集群中其他在线的持有槽的主节点投票到故障主节点的从节点们

所以集群不必另外使用Redis Sentinel。


### 集群分片策略

常见的集群分片算法有：

* 一般哈希算法
* 一致性哈希算法
* Hash Slot算法

Redis采用的是Hash Slot

#### 一般哈希算法

计算方式：hash(key)%N
缺点：如果增加一个redis，映射公式变成了 hash(key)%(N+1)
​	    如果一个redis宕机了，映射公式变成了 hash(key)%(N-1)
​	    在以上两种情况下，几乎所有的缓存都失效了。

#### 一致性哈希算法

先构造出一个长度为2^32整数环，根据节点名称的hash值（分布在[0,2^32-1]）放到这个环上。现在要存放资源，根据资源的Key的Hash值（也是分布在[0,2^32-1]），在环上顺时针的找到离它最近的一个节点，就建立了资源和节点的映射关系。

* 优点：一个节点宕机时，上面的数据转移到顺时针的下一个节点中，新增一个节点时，也只需要将部分数据迁移到这个节点中，对其他节点的影响很小
* 缺点：由于数据在环上分布不均，可能存在某个节点存储的数据比较多，那么当他宕机的时候，会导致大量数据涌入下一个节点中，把另一个节点打挂了，然后所有节点都挂了
* 改进：引进了虚拟节点的概念，想象在这个环上有很多“虚拟节点”，数据的存储是沿着环的顺时针方向找一个虚拟节点，每个虚拟节点都会关联到一个真实节点

#### Hash Slot算法

Redis采用的是Hash Slot分片算法，用来计算key存储位置的。集群将整个数据库分为16384个槽位slot，所有key-value数据都存储在这些slot中的某一个上。一个slot槽位可以存放多个数据，key的槽位计算公式为：slot_number=CRC16(key)%16384，其中CRC16为16位的循环冗余校验和函数。
客户端可能会挑选任意一个redis实例去发送命令，每个redis实例接收到命令，都会计算key对应的hash slot，如果在本地就在本地处理，否则返回moved给客户端，让客户端进行重定向到对应的节点执行命令(实现得好一点的smart客户端会缓存键-slot-节点的映射关系来获得性能提升).

**那为什么是16384个槽呢?**

ps:CRC16算法产生的hash值有16bit，该算法可以产生2^16-=65536个值。换句话说，值是分布在0~65535之间。那作者在做mod运算的时候，为什么不mod65536，而选择mod16384？[作者解答](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fantirez%2Fredis%2Fissues%2F2576)

在redis节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，16384=16k，在发送心跳包时使用char进行bitmap压缩后是`2k（2 * 8 (8 bit) * 1024(1k) = 2K）`，也就是说使用2k的空间创建了16k的槽数。

虽然使用CRC16算法最多可以分配65535（2^16-1）个槽位，65535=65k，压缩后就是`8k（8 * 8 (8 bit) * 1024(1k) = 8K）`，也就是说需要需要8k的心跳包，作者认为这样做不太值得；并且一般情况下一个redis集群不会有超过1000个master节点，所以16k的槽位是个比较合适的选择。


## 缓存雪崩是啥?咋处理?

是指**大面积的缓存失效，打崩了DB.**

打个比方, 如果所有首页的Key失效时间都是12小时，中午12点刷新的，我零点有个秒杀活动大量用户涌入，假设当时每秒 6000 个请求，本来缓存在可以扛住每秒 5000 个请求，但是缓存当时所有的Key都失效了。此时 1 秒 6000 个请求全部落数据库，数据库必然扛不住.

处理方案: 

* key随机过期
* key永不过期, 比如开个单独线程去定时更新缓存
* 高可用, 如果Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效的问题
* 隔离服务, 限流降级


## 缓存穿透是啥?咋处理?

是指**缓存和数据库中都没有的数据，而用户不断发起请求，严重会击垮数据库** 

我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。

处理方案:

* 缓存穿透我会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。
* 布隆过滤器, 把存在的key提前存放好在布隆过滤器中, 当查询的时候快速判断出你这个Key是否在数据库中存在, 不存在则直接return


## 缓存击穿是啥?咋处理?

是指**持续的大并发的访问一个热点数据, 当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库**

这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常**热点**，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

处理方案:

* key永不过期, 比如开个单独线程去定时更新缓存
* 互斥锁, 在key失效的瞬间, 只允许一个查询操作的线程A去查询数据库并重建缓存并上互斥锁, 其他的查询操作线程全部等待线程A操作完了再从缓存里取数据


# etcd

raft 参考 https://www.jianshu.com/p/5aed73b288f7

etcd 是一个 Go 语言编写的分布式、高可用的**强一致性**键值存储系统，用于提供可靠的分布式键值(key-value)存储、配置共享和服务发现等功能。 etcd可以用于存储关键数据和实现分布式调度，它在现代化的集群运行中能够起到关键性的作用。


## etcd概念术语

- Raft： etcd所采用的保证分布式系统强一致性的算法。
- Node： 一个Raft状态机实例。
- Member： 一个etcd实例。它管理着一个Node，并且可以为客户端请求提供服务。
- Cluster： 由多个Member构成可以协同工作的etcd集群。
- Peer： 对同一个etcd集群中另外一个Member的称呼。
- Client： 向etcd集群发送HTTP请求的客户端。
- WAL： 预写式日志，etcd用于持久化存储的日志格式。
- snapshot： etcd防止WAL文件过多而设置的快照，存储etcd数据状态。
- Proxy： etcd的一种模式，为etcd集群提供反向代理服务。
- Leader： Raft算法中通过竞选而产生的处理所有数据提交的节点。
- Follower： 竞选失败的节点作为Raft中的从属节点，为算法提供强一致性保证。
- Candidate： 当Follower超过一定时间接收不到Leader的心跳时转变为Candidate开始竞选。
- Term： 某个节点成为Leader到下一次竞选时间，称为一个Term。
- Index： 数据项编号。Raft中通过Term和Index来定位数据。


## 数据读写顺序

为了保证数据的强一致性，etcd 集群中所有的数据流向都是一个方向，从 Leader （主节点）流向 Follower，也就是所有 Follower 的数据必须与 Leader 保持一致，如果不一致会被覆盖。

用户对于 etcd 集群所有节点进行读写

- 读取： 由于集群所有节点数据是强一致性的，读取可以从集群中随便哪个节点进行读取数据
- 写入： etcd 集群有 leader，如果写入往 leader 写入，可以直接写入，然后然后Leader节点会把写入分发给所有 Follower，如果往 follower 写入，然后Leader节点会把写入分发给所有 Follower


## leader 选举

假设三个节点的集群，三个节点上均运行 Timer（每个 Timer 持续时间是随机的），Raft算法使用随机 Timer 来初始化 Leader 选举流程，第一个节点率先完成了 Timer，随后它就会向其他两个节点发送成为 Leader 的请求，其他节点接收到请求后会以投票回应然后第一个节点被选举为 Leader。

成为 Leader 后，该节点会以固定时间间隔向其他节点发送通知，确保自己仍是Leader。有些情况下当 Follower 们收不到 Leader 的通知后，比如说 Leader 节点宕机或者失去了连接，其他节点会重复之前选举过程选举出新的 Leader。


## 判断数据是否写入

etcd 认为写入请求被 Leader 节点处理并分发给了多数节点后，就是一个成功的写入。那么多少节点如何判定呢，假设总结点数是 N，那么多数节点 Quorum=N/2+1。关于如何确定 etcd 集群应该有多少个节点的问题，上图的左侧的图表给出了集群中节点总数(Instances)对应的 Quorum 数量，用 Instances 减去 Quorom 就是集群中容错节点（允许出故障的节点）的数量。

所以在集群中推荐的最少节点数量是3个，因为1和2个节点的容错节点数都是0，一旦有一个节点宕掉整个集群就不能正常工作了。


## etcd 架构及解析2.1 架构图

![](//im/noodle_plang/etcd/etcd_%20architecture.jpeg)


### 架构解析

从 etcd 的架构图中我们可以看到，etcd 主要分为四个部分。

- HTTP Server： 用于处理用户发送的 API 请求以及其它 etcd 节点的同步与心跳信息请求。
- Store： 用于处理 etcd 支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等等，是 etcd 对用户提供的大多数 API 功能的具体实现。
- Raft： Raft 强一致性算法的具体实现，是 etcd 的核心。
- WAL： Write Ahead Log（预写式日志），是 etcd 的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引以外，etcd 就通过 WAL 进行持久化存储。WAL 中，所有的数据提交前都会事先记录日志。

Snapshot 是为了防止数据过多而进行的状态快照；Entry 表示存储的具体日志内容。

通常，一个用户的请求发送过来，会经由 HTTP Server 转发给 Store 进行具体的事务处理，如果涉及到节点的修改，则交给 Raft 模块进行状态的变更、日志的记录，然后再同步给别的 etcd 节点以确认数据提交，最后进行数据的提交，再次同步。


# misc

- hashmap 是怎样实现的？


## Base64 的原理？编码后比编码前是大了还是小了。

结论:

大了. 因为Base64 编码本质上是一种将二进制数据转成文本数据的方案。对于非二进制数据，是先将其转换成二进制形式，然后每连续 6 比特（2 的 6 次方 = 64）计算其十进制值，根据该值在上面的索引表中找到对应的字符，最终得到一个文本字符串。也就是说, 每 3 个原始字符编码成 4 个字符，如果原始字符串长度不能被 3 整除，那怎么办？使用 0 值来补充原始字符串。


### base64的原理

Base64 编码之所以称为 Base64，是因为其使用 64 个字符来对任意数据进行编码，同理有 Base32、Base16 编码。标准 Base64 编码使用的 64 个字符为：

![](/img/noodle_plan/http/XHFMRvxfez4OVtr.jpg)

这 64 个字符是各种字符编码（比如 ASCII 编码）所使用字符的子集，基本，并且可打印。唯一有点特殊的是最后两个字符，因对最后两个字符的选择不同，Base64 编码又有很多变种，比如 Base64 URL 编码。

Base64 编码本质上是一种将二进制数据转成文本数据的方案。对于非二进制数据，是先将其转换成二进制形式，然后每连续 6 比特（2 的 6 次方 = 64）计算其十进制值，根据该值在上面的索引表中找到对应的字符，最终得到一个文本字符串。

假设我们要对 `Hello!` 进行 Base64 编码，按照 ASCII 表，其转换过程如下图所示：

![](/img/noodle_plan/http/tJnClQsjc4WMGhB.jpg)

可知 `Hello!` 的 Base64 编码结果为 `SGVsbG8h` ，原始字符串长度为 6 个字符，编码后长度为 8 个字符，每 3 个原始字符经 Base64 编码成 4 个字符，编码前后长度比 4/3，这个长度比很重要 - 比原始字符串长度短，则需要使用更大的编码字符集，这并不我们想要的；长度比越大，则需要传输越多的字符，传输时间越长。Base64 应用广泛的原因是在字符集大小与长度比之间取得一个较好的平衡，适用于各种场景。

是不是觉得 Base64 编码原理很简单？

但这里需要注意一个点：Base64 编码是每 3 个原始字符编码成 4 个字符，如果原始字符串长度不能被 3 整除，那怎么办？使用 0 值来补充原始字符串。

以 `Hello!!` 为例，其转换过程为：

![](/img/noodle_plan/http/5URB8nVis9ljwYe.jpg)

_注：图表中蓝色背景的二进制 0 值是额外补充的。_

`Hello!!` Base64 编码的结果为 `SGVsbG8hIQAA` 。最后 2 个零值只是为了 Base64 编码而补充的，在原始字符中并没有对应的字符，那么 Base64 编码结果中的最后两个字符 `AA` 实际不带有效信息，所以需要特殊处理，以免解码错误。

标准 Base64 编码通常用 `=` 字符来替换最后的 `A`，即编码结果为 `SGVsbG8hIQ==`。因为 `=` 字符并不在 Base64 编码索引表中，其意义在于结束符号，在 Base64 解码时遇到 `=` 时即可知道一个 Base64 编码字符串结束。

如果 Base64 编码字符串不会相互拼接再传输，那么最后的 `=` 也可以省略，解码时如果发现 Base64 编码字符串长度不能被 4 整除，则先补充 `=` 字符，再解码即可。

解码是对编码的逆向操作，但注意一点：**对于最后的两个 `=` 字符，转换成两个 `A` 字符，再转成对应的两个 6 比特二进制 0 值，接着转成原始字符之前，需要将最后的两个 6 比特二进制 0 值丢弃，因为它们实际上不携带有效信息**。


## utf8编码和unicode字符集

说到utf8，就不得不说一下unicode了。  Unicode是一个很大的集合，每一个unicode对应一个符号，不管是中文的汉字，英文字符，日文，韩文等等。现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如，U+0639表示阿拉伯字母 Ain，U+0041表示英语的大写字母A，U+4E25表示汉字“严”。具体的符号对应表，可以查询unicode.org，或者专门的汉字对应表。

需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。

比如，汉字“严”的unicode是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。

这里就有两个严重的问题，第一个问题是：如何才能区别unicode和ascii？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是：我们已经知道，英文字母只用一个字节表示就够了，如果unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。

它们造成的结果是：

1）出现了unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示unicode。

2）unicode在很长一段时间内无法推广，直到互联网的出现。

### UTF-8

互联网的普及，强烈要求出现一种统一的编码方式。UTF-8就是在互联网上使用最广的一种unicode的实现方式。其他实现方式还包括UTF-16和UTF-32，不过在互联网上基本不用。重复一遍，这里的关系是，UTF-8是Unicode的实现方式之一。

UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。

UTF-8的编码规则很简单，只有二条：

* 1）对于单字节的符号，字节的第一位（字节的最高位）设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。

* 2）对于n字节的符号（n>1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。

下表总结了编码规则，字母x表示可用编码的位。

Unicode符号范围 UTF-8编码方式(十六进制) | （二进制）
```
—————+———————————————————————
0000 0000-0000 007F | 0xxxxxxx
0000 0080-0000 07FF | 110xxxxx 10xxxxxx
0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx
0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
```
下面，还是以汉字“严”为例，演示如何实现UTF-8编码：
已知“严”的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此“严”的UTF-8编码需要三个字节，即格式是“1110xxxx 10xxxxxx 10xxxxxx”。然后，从“严”的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，“严”的UTF-8编码是“11100100 10111000 10100101”，转换成十六进制就是E4B8A5。

- 非递归实现树的后序遍历。（这个比较有意思，大家可以试下）
- 秒杀系统的实现?



--------------------------------------------------------


# 以下是废弃的不用看了

pass


# 实操工具类

1. [ ] 可能会问docker, 需要把自己的项目docker化一波
2. [x] etcd


# 实操写代码类

5. [ ] 用asio+msgpack_rpc和参考了asiocore的kcpp来优化一波realtime-server
6. [ ] 完成jiffy

2. [x] 算法复习博客中的
4. [x] kcp rdc 握手 双通道


# 阅读书籍类

<!-- - [ ] malloc -->
<!-- - [ ] makefile -->
- [ ]  mysql
  - [ ] bin log
<!-- - [ ]   模板头文件可以放在cpp里么? 可以但是cpp里必须用到啥类型就要显示实例化啥类型 -->
<!-- - [ ] map insert 和中括号 -->
- [ ] text blob
<!-- - [ ] 虚拟内存, 页是啥意思 -->
- [ ] 查脉脉2.3 3.1薪资
<!-- - [ ] 为什么分代码段和数据段 -->
- [ ] 热备冷备
<!-- - [ ] 如何查看多个文件的同个字符串? grep -r -->
<!-- - [ ] 容器删除要注意什么? 迭代器失效问题 -->
- [ ] 共享内存, 如果core了会咋样
- [ ] 火焰图工具怎么做的? ptrace 么? ptrace是啥? perf
<!-- - [ ] 定位new -->
<!-- - [ ] c++一个空类会生成什么 (默认构造/析构(非虚)/赋值运算符/默认拷贝/取地址/const取地址) -->

<!-- Linux知识: SIGINT, SIGTERM, SIGSR1, SIGABRT, SIGSEGV,  -->
<!-- 进程状态(僵尸/孤儿), linux线程本质(LWP), 页表 -->
<!-- 服务器环境: 常用系统路径作用(/etc, /usr, /proc/), apt包管理使用(debian), -->
<!-- HTTP: get和post区别.  -->
<!-- query string 格式与编码; -->
<!-- curl的使用. -->
  <!-- 认识常见http header; 稍微了解https握手过程 -->
 
## 开发环境与工具

<!-- Makefile了解，能编写有多个文件的简单Makefile -->
<!-- CMake的使用.  -->
<!-- 编译, 链接过程原理; 静态库/动态库区别;  C++ name mangling, -->
<!-- ABI兼容概念； ldd命令(列出依赖库), nm命令(列出符号表), objdump命令(反编译啥的) -->
<!-- coredump本质是啥(出事得时候得程序内存快照) -->
<!-- 要-g才能用gdb查看coredump.   -->
<!-- gdb的bt, p XXX, info XXX, frame XXX, thread... -->

<!-- gcc编译常用选项:
 -D(D选项是用来在使用gcc/g++编译的时候定义宏的, gcc -DNAME=Peter -D 后面跟 key=value 表示定义key这个宏，它的内容是value)
 -I(指定头文件路径, 在你是用 #include "file" 的时候, gcc/g++ 会先在当前目录查找你所制定的头文件, 如果没有找到, 他回到默认的头文件目录找, 如果使用 -I 制定了 目录,他会先在你所制定的目录查找, 然后再按常规的顺序去找。

  对于 #include<file>, gcc/g++ 会到 -I 制定的目录查找, 查找不到, 然后将到系统的默认的头文件目录查找 。)
 -L(制定编译的时候，搜索库的路径) ...
 -l(选择链接得library)
  -w(小写w)的意思是关闭编译时的警告，也就是编译后不显示任何warning，因为有时在编译之后编译器会显示一些例如数据转换之类的警告，这些警告是我们平时可以忽略的。
-Wall选项意思是编译后显示所有警告。
-W选项类似-Wall，会显示警告，但是只显示编译器认为会出现错误的警告。 -->

<!-- vscode的使用，掌握remote插件使用(远程连服务器开发调试) -->
 
## C/C++进阶

<!-- RAII的用法(各种guard)  -->
<!-- C++11: move, -->
 <!-- lambda(语法及变量捕捉, 生命周期), -->
  <!-- shared_from_this 原理 -->
<!-- unordered_map使用,  -->
 <!-- function对象, shared_ptr, weak_ptr -->
<!-- dynamic_cast, reinterpret_cast, static_cast, const_cast. -->
<!-- 线程相关: thread, mutex, atomic变量 -->
<!-- SIGSEGV信号--segment fault常见原因 -->
<!-- 字节流指针解引用. -->
 <!-- 跨平台字节对齐问题(SIGBUS) -->
<!-- profile工具: tcmalloc的heap profiler, gperf.  -->
<!-- 了解ASAN查找内存越界问题 -->
<!-- 查内存泄漏工具 -->

## 数据库

<!-- mongo是直接存在内存里的嘛? 怎么持久化的? -->
<!-- mongo高可用? -->
<!-- MongoDB的CRUD基本使用. （官方文档教程） -->
<!-- 索引的使用及基本原理.  -->
MongoDB的sharding原理, shard key的类型及数值分布对其影响:
    MongoDB支持两种类型的shard key：

      - Hashed，数据库根据指定的字段值，算出一个哈希值，然后根据这个哈希值把数据写入相应的服务器中。它的好处是数据会分布的比较均匀，但是它只能把一个字段指定为shard key，另外对于范围的操作，它更多是一个广播的操作，没有精确地路由。
      - Ranged，按照指定字段的值的范围进行划分，支持复合shard key。这个就要求对字段值的范围有比较深入的了解，对未来也有一个相对清晰的把握。相对哈希，这种方式就可以有比较精确的路由。但是它也可能会带来数据分布不均匀，负载不能完全均衡的问题。
<!-- redis基本使用. 常用数据结构的应用场合. -->


<!-- - 看go, 写上登陆夫 -->
- [ ] 全球匹配怎么做?
<!-- - [ ] gdb core怎么弄 -->
- [ ] 全球同服怎么做?
- [ ] 根据登入登出日志画出在线曲线?

- [ ] 了解宝可梦/使命召唤的历史和玩法, 看看游戏和动画视频啥的
- [ ] 桶排序/线段树/统计树/排序树

- [x] 文件夹读写执行权限(文件夹得执行权限会影响其读权限和写权限, 进都进不去还想读写?)
- [x] 无锁队列原理是否一定比有锁快?(不一定, 如果临界区小因为有上下文切换则mutex慢, 再来看lockfree的spin，一般都遵循一个固定的格式：先把一个不变的值X存到某个局部变量A里，然后做一些计算，计算/生成一个新的对象，然后做一个CAS操作，判断A和X还是不是相等的，如果是，那么这次CAS就算成功了，否则再来一遍。如果上面这个loop里面“计算/生成一个新的对象”非常耗时并且contention很严重，那么lockfree性能有时会比mutex差。另外lockfree不断地spin引起的CPU同步cacheline的开销也比mutex版本的大。关于ABA问题)
- [x] msgpack pb 对比
- [x] mock
- [x] jit编译器的原理
7. [x] lockfree 队列原理
- [x] 怎么实现一个协程库?参考gevent, 协程池又是啥
- [x] 其他线程能看到另一个线程new出来的堆上东西
- [x] 线程是怎么切换的，上下文是啥？
- [x] 函数栈帧原理
- [x] 适配器模式
- [x] 纠删码(Erasure Coding)
- [x] pch是啥, 怎么提高编译速度的?
- [x] qos是啥?限速?答案: 从国外会国内也有很多条路，假设 aws 日本到国内，你给的钱多，qos 就把你放到质量好的链路；你免费，qos 就把你放到常规的链路上，高峰期丢包，中间运营商爱出故障
8. [x] python进阶，他的gc和，为啥不释放内存？查阅了关于python的内存机制的文章, 了解了垃圾回收的分代回收/引用计数/处理循环引用机制以及通过gc module和objgraph查询内存泄漏和循环引用的方法
8. [x] 多进程能利用上多核cpu么?
1. [x] pytho gc卡顿
1. [x] shared_ptr是否为线程安全的, 他的引用计数是安全的, 但是shared_ptr的读写则不是, 需要加锁操作
2. [x] 客户端如何同步服务器时间
8. [x] python为啥不是真的多线程: 他是真的多线程, 不过同一时间只有一个线程能拿到global interpreter lock(GIL), 所以看起来就像是单线程一样
- [x] 博客中noodle的文章
3. [x] mongodb
1. [x] 行为树
5. [x] 状态机
1. [x] 技能编辑器
- [x] 服务发现原理
- [x] 多线程编程防止死锁: 顺序加锁, 可以先释放占有的锁，然后过一段时间再试
9. [x] mro问题
6. [x] 登录流程, 并对比市面其他的token登录流程
2. [x] redis, 连接池还没看
4. [x] 排行榜, 四亿玩家的实时排行榜怎么撸?
10. [x] http post form


# 阅读代码类

<!-- 3. [  ] 时间轮, 最小堆定时器是啥? 看看muduo的定时器是啥样的, 跟最小堆实现有啥优势?最小堆是啥 -->
6. [ ] 排队服务
4. [ ] msgpack rpc, 模板复习

- [x] asiocore 怎么加密内容的? key在哪儿? 答案: 类似于https那一套
5. [x] epoll那一套可能要看一哈, 水平触发/边缘触发啥的, 要弄清楚水平触发和边缘触发的真正区别
- [x] asiocore怎么检查超时的?高效么?
6. [x] 抽空看一波muduo, 看看他怎么实现类似boost的strand的, 不然简历写网络库有点虚, 不然logger保序输出有点虚
2. [x] battle tick的fps是20? 会不会受到poll影响?
3. [x] 客户端逻辑帧率是多少?跟服务器帧率不同会有什么问题? 答:客户端若高则等, 若低则补帧
4. [x] 客户端比如像双棍的绕着转的技能, 是完全靠服务器同步pos的嘛?
5. [x] python占用比怎么算的?
4. [x] 复习c++本身找点题来做
2. [x] service gate
1. [x] aoi,  可知九宫格内广播对象集合是固定的，每次 AOI 事件不需要浪费 CPU 计算集合，链表的 插入删除在 O(1)内完成，但九宫格范围比avatar的实际视野要大，需要发送视野外的额外的 avatar 对象消息，浪费带宽，在边界处往返移动尤为明显。

      十字链表法的优点在于可以较准确计算有效的AOI 范围对象集合，大大减少视野外的无效 AOI 消息，节省网络封包量。缺点在于每次插入和移动时，需要计算AOI对象集合，比较 消耗 CPU。计算消耗取决于视野范围内的活动的avatar 对象数量，以及进出场景的频繁程 度。比较适合活动avatar不多，移动和进出场景不频繁，固定NPC 为主的PVE 向游戏。而九宫格法几乎不需要计算，缺点就是视野范围外的无效封包量很多。
2. [x] asiocore的kcp怎么处理主动disconnect的?经查证, 是直接设置两个已disconnected的标志位, 然后其他地方再判断之后做相应的逻辑


# 简历内容

- [ ] 简历每个可能思维扩散得对策提前写

2. [x] wx和my的km文章也要写, 比如aoi啥的
3. [x] py找找姜的面试题，网上常用题
5. [x] 写上zc经验
6. [x] kcp弱网络环境提升方案: dupack以及dupacks以及冗余rdc_data
4. [x] 异步日志可以看一下, 把wx的优化写上
9. [x] 查看g90doc看看wx他们写的东西, 充作zc经验, 看看能否弄到简历
1. [x] 把wx优化写进去延迟优化orm啥的- [x] 把晋升申请的文档梳理以下放到简历里
3. [x] cpp找找冰川, 大梦龙图的面试题，网上常用题


# 项目相关的阅读

4. [ ] 项目中的全局搜索怎么做的?模糊搜索算法又是啥?

<!-- 1. [ ] gate和gameManager和dbmanager有啥用 -->
<!-- 4. [ ] #6937 服务端自主-战斗服、微服务 rolling restart设计 -->
5. [ ] 运营指令那一套是怎么撸的

3. [x] 系统与功能 #21253 网络延迟稳定定位及优化
1. [x] 90的观战和录像是怎么做的?是指令重放吗?还是啥?
2. [x] 90录像怎么传上去的?那么大
2. [x] 在类里面新加一个变量reload后老的对象是没有这个新的成员变量的那新的对象呢？比如在CompCastSkill上加个成员变量test_reload = 1, 然后在start_cast上上print test_reload , reload后在训练场里加入一个新玩家, 看看他会不会print 1; 经查证, 新玩家是会打印1的, 老玩家会报trackback没有test_reload这个成员

-------------------------------------------------------------------------------------------

# 以下皆为杂项待归纳

- [ ] 系统与功能 #21253 网络延迟稳定定位及优化 
- [ ] #21733 [压测修复] 好友压测问题修复

- [x] #21256问题修复 - apply_friend时redis连接耗尽问题
- [ ] #18061 MongoDB报错优化
- [ ] #18060 MongoDB存盘报警
- [x] #14793 压测优化 - 微服务环境下的MongoDB连接优化
- [x] #14547 压测修复 - FriendService redis连接问题

- [ ] #6937 服务端自主-战斗服、微服务 rolling restart设计
- [ ] #6935 服务端自主-登录服设计
- [ ] #6936 服务端自主-游戏服、战斗服、微服务弹性扩缩容设计
- [ ] #9761 MatchService效率优化

- [ ] #15678Flyer C++化 服务器同步修改

- [ ] #15252 反作弊机制 - 录像记录
- [ ] #15262 反作弊机制 - 离线分析功能
- [ ] #15804 反作弊机制 - 离线分析功能 - 离线播放功能预研

